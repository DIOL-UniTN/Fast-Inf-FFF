{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "464058eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='leocus4', repo_name='TinyFFF', mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ad620fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Training on {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bbe9647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07f4adae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_size_fc(model, list_of_fc_layers, list_of_fc_sparsity, verbose=False):\n",
    "    '''\n",
    "    model has to be sublass of nn.Module\n",
    "        check the subclass with: issubclass(sub, sup), return true if sub is sublcass of sup\n",
    "                                 isinstance(sub_instance, sup), return true if is sub_instance is subclass of sup\n",
    "    list_of_fc_layers: list of fully connected layer OF THE MODEL (should be a pointer to layer of model)\n",
    "    list_of_fc_sparsity: list of the sparsity for each fully connected layer\n",
    "    '''\n",
    "    assert isinstance(model, nn.Module), \"The model is not a subclass of torch.nn.Module\"\n",
    "    assert len(list_of_fc_layers) == len(list_of_fc_sparsity), \"The lists should be of the same length\"\n",
    "    kb = 1000\n",
    "    verbose and print(\"-------------------------------------------------------------------------------------------\")\n",
    "    model_size_no_sparsity = 0\n",
    "    for param in model.parameters():\n",
    "        model_size_no_sparsity += param.nelement() * param.element_size()\n",
    "    for buffer in model.buffers():\n",
    "        model_size_no_sparsity += buffer.nelement() * buffer.element_size()\n",
    "    \n",
    "    total_size_no_sparsity = 0\n",
    "    total_size_with_sparsity = 0\n",
    "    total_size_with_sparsity_CSC = 0\n",
    "    \n",
    "    size_layer_list = []\n",
    "    num = 0\n",
    "    for fc_layer, sparsity in zip(list_of_fc_layers, list_of_fc_sparsity):\n",
    "        num += 1\n",
    "        # get size\n",
    "        verbose and print(\"Layer \" + str(num), fc_layer)\n",
    "        weight = fc_layer.nelement() * fc_layer.element_size()\n",
    "        \n",
    "        # save in no sparsity\n",
    "        total_size_no_sparsity += weight\n",
    "        \n",
    "        # set sparsity\n",
    "        weight = min(1, 2 * sparsity) * weight\n",
    "        \n",
    "        # FROM Representation\n",
    "        if (sparsity <= 0.5): # Dipende dall'analisi che vuoi fare\n",
    "            if (len(list(fc_layer.shape)) == 3):\n",
    "                verbose and print(\"Layer require additional\", fc_layer.shape[0], \"variables, total size with 4 bytes:\", fc_layer.shape[0]*4 / kb)\n",
    "                total_size_with_sparsity_CSC += (fc_layer.shape[0]*4) # number of filter\n",
    "            elif (len(list(fc_layer.shape)) == 2):\n",
    "                total_size_with_sparsity_CSC += (fc_layer.shape[1] + 1)*4 # number of column\n",
    "                verbose and print(\"Layer require additional\", fc_layer.shape[1]+1, \"variables, total size with 4 bytes:\", (fc_layer.shape[1]+1)*4 / kb)\n",
    "            \n",
    "        total_size_with_sparsity_CSC += weight\n",
    "        \n",
    "        # save in with sparsity\n",
    "        total_size_with_sparsity += weight\n",
    "        \n",
    "        size_layer_list.append(weight)\n",
    "        \n",
    "        # print total - print weight - print bias\n",
    "        verbose and print(\"Layer \"+str(num)+\":\\t\\t\", (weight) / kb,\n",
    "              \"KB, \\tweight:\\t\", weight / kb, \"KB\")\n",
    "    \n",
    "    # print total no sparisty\n",
    "    verbose and print(\"Size FC Layer (no sparsity):\\t\", total_size_no_sparsity / kb,\"KB\")\n",
    "    \n",
    "    # print total with sparsity\n",
    "    verbose and print(\"Size FC Layer (with sparsity):\\t\", total_size_with_sparsity / kb,\"KB\")\n",
    "    \n",
    "    # print model total - total no sparsity\n",
    "    verbose and print(\"Total Size no sparsity:\\t\\t\", model_size_no_sparsity / kb ,\"KB\")\n",
    "    \n",
    "    # print model total - total no sparisty + total with sparsity\n",
    "    model_size_with_sparsity = model_size_no_sparsity - total_size_no_sparsity + total_size_with_sparsity\n",
    "    verbose and print(\"Total Size with sparsity:\\t\", model_size_with_sparsity / kb,\"KB\")\n",
    "    \n",
    "    # print model total - total no sparisty + total with sparsity and CSC\n",
    "    model_size_with_sparsity_CSC = model_size_no_sparsity - total_size_no_sparsity + total_size_with_sparsity_CSC\n",
    "    verbose and print(\"Total Size with sparsity and CSC representation:\\t\", model_size_with_sparsity_CSC / kb,\"KB\")\n",
    "    \n",
    "    verbose and print(\"-------------------------------------------------------------------------------------------\")\n",
    "    \n",
    "    return model_size_with_sparsity, model_size_with_sparsity_CSC, size_layer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3266534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_compression(model, list_of_fc_layers, list_of_fc_sparsity, learning_rate, num_epochs, train_loader,\n",
    "                        test_loader,model_device,val_loader=None, model_name=None, given_criterion=None,\n",
    "                        calculate_inputs=None,calculate_outputs=None, history=False, regularizerParam = 0):\n",
    "    '''\n",
    "    model has to be sublass of nn.Module\n",
    "        check the subclass with: issubclass(sub, sup), return true if sub is sublcass of sup\n",
    "                                 isinstance(sub_instance, sup), return true if is sub_instance is subclass of sup\n",
    "    list_of_fc_layers: list of fully connected layer OF THE MODEL (should be a pointer to layer of model)\n",
    "    list_of_fc_sparsity: list of the sparsity for each fully connected layer\n",
    "    NOTE - Sparsity applied only to weight of FC, not on bias\n",
    "    NOTE - The list are modified during execution, so are copied with list.copy() to avoid changing the original list\n",
    "    '''\n",
    "    assert isinstance(model, nn.Module), \"The model is not a subclass of torch.nn.Module\"\n",
    "    assert len(list_of_fc_layers) == len(list_of_fc_sparsity), \"The lists should be of the same length\"\n",
    "    # asset sparsity between 0 and 1\n",
    "    valid_sparsity = True\n",
    "    for sparsity in list_of_fc_sparsity:\n",
    "        if (sparsity > 1) or (sparsity < 0):\n",
    "            valid_sparsity = False\n",
    "    assert valid_sparsity, \"The sparsity value must be between 0 and 1\"\n",
    "    list_of_fc_layers = list_of_fc_layers.copy()\n",
    "    list_of_fc_sparsity = list_of_fc_sparsity.copy()\n",
    "    # The idea is get the model, set all parameter to not require gradient, set fully connected layer to require gradient,\n",
    "    # perform training\n",
    "    \n",
    "    # disabling parameters\n",
    "    for name, param in model.named_parameters():\n",
    "        print(\"Disabling:\", name)\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # activating fully connected layers only if its sparsity is > 0\n",
    "    # if a layer has sparsity equal to zero we can override with 0\n",
    "    # if all sparsity is set to 1, compression is not requested\n",
    "    sparseTraining = False\n",
    "    for fc_layer, sparsity in zip(list_of_fc_layers, list_of_fc_sparsity):\n",
    "        if (sparsity == 1):\n",
    "            #if (sparseTraining):\n",
    "            print(\"Activating:\", fc_layer.shape)\n",
    "            fc_layer.requires_grad = True\n",
    "        elif (sparsity > 0):\n",
    "            print(\"Activating:\", fc_layer.shape)\n",
    "            fc_layer.requires_grad = True\n",
    "        else:\n",
    "            fc_layer.weight = torch.nn.Parameter(torch.zeros_like(fc_layer.weight), requires_grad=False)\n",
    "            # delete from the list (since no need to update them)\n",
    "            list_of_fc_layers.remove(fc_layer)\n",
    "            list_of_fc_sparsity.remove(sparsity)\n",
    "            \n",
    "        if (sparsity < 1):\n",
    "            sparseTraining = True\n",
    "    \n",
    "    acc = 0\n",
    "    # TEST - compute accuracy\n",
    "    accuracyHistory = []\n",
    "    lastCorrect = 0\n",
    "    totalPredictions = 0\n",
    "    numberOfUpdates = len(test_loader)\n",
    "        \n",
    "    if not (sparseTraining):\n",
    "        print(\"No need to perform compression, all layers's sparsity is set to 1\")\n",
    "    else: # PERFORM TRAINING - COMPRESSION\n",
    "        \n",
    "        # set up\n",
    "        criterion = nn.NLLLoss()\n",
    "        if given_criterion:\n",
    "            criterion = given_criterion\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        #optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        n_total_steps = len(train_loader)\n",
    "        \n",
    "        # to save best results\n",
    "        best_val_epoch, best_val_loss, best_val_acc, best_acc_epoch = 0, 1e6, 0, 0\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            model.train()\n",
    "            for i, (inputs, labels) in enumerate(train_loader):\n",
    "                \n",
    "                inputs = inputs.to(model_device)\n",
    "                labels = labels.to(model_device)\n",
    "                                \n",
    "                # Forward pass\n",
    "                \n",
    "                # preforward\n",
    "                if calculate_inputs:\n",
    "                    inputs = calculate_inputs(inputs)\n",
    "                \n",
    "                # forward\n",
    "                if calculate_outputs:\n",
    "                    outputs = calculate_outputs(inputs)\n",
    "                else:\n",
    "                    outputs = model.forward(inputs)\n",
    "                \n",
    "                # Regularization\n",
    "                regularizer = 0\n",
    "                if (regularizerParam != 0):\n",
    "                    for layer in list_of_fc_layers:\n",
    "                        regularizer += (torch.norm(layer.weight)**2)\n",
    "                # Loss\n",
    "                loss = criterion(outputs, labels) + (regularizer * regularizerParam)\n",
    "                \n",
    "                # Backward and optimize\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # apply hardthreshold - in the list we have only layer with require_grad = True\n",
    "                for fc_layer, sparsity in zip(list_of_fc_layers, list_of_fc_sparsity):\n",
    "                    layer = fc_layer.data\n",
    "                    new_layer = hardThreshold(layer, sparsity)\n",
    "                    with torch.no_grad():\n",
    "                        fc_layer.data = torch.FloatTensor(new_layer).to(model_device)\n",
    "                \n",
    "                # print Accuracy\n",
    "                if (i+1) % 100 == 0:\n",
    "                    print (f'Epoch [{epoch+1}/{num_epochs}], Step[{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "            \n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step[{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "            \n",
    "            # Use Validation Set at each epochs to pick the most \n",
    "            if (val_loader and model_name):\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    v_loss = 0\n",
    "                    n_correct = 0\n",
    "                    n_samples = 0\n",
    "                    n_iterations = 0\n",
    "                    for inputs, labels in test_loader:\n",
    "                        inputs = inputs.to(model_device)\n",
    "                        labels = labels.to(model_device)\n",
    "                        # Forward pass\n",
    "                \n",
    "                        # preforward\n",
    "                        if calculate_inputs:\n",
    "                            inputs = calculate_inputs(inputs)\n",
    "                        outputs = 0 \n",
    "                        # forward\n",
    "                        if calculate_outputs:\n",
    "                            outputs = calculate_outputs(inputs)\n",
    "                        else:\n",
    "                            outputs = model.forward(inputs)\n",
    "                        \n",
    "                        # for calculating v_loss\n",
    "                        loss = criterion(outputs, labels)                       \n",
    "                        v_loss += loss.item()\n",
    "                        n_iterations += 1\n",
    "                        \n",
    "                        # max returns (value, index)\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        n_samples += labels.size(0)\n",
    "                        n_correct += (predicted == labels).sum().item()\n",
    "                    \n",
    "                    # Val test completed, now checking the results\n",
    "                    v_loss = v_loss/(n_iterations)\n",
    "                    v_loss = round(v_loss, 5)\n",
    "                    v_acc = round(100*(n_correct / n_samples), 5)\n",
    "                    \n",
    "                    if v_acc >= best_val_acc:\n",
    "                        torch.save(model.state_dict(), model_name+\"_acc.h5\")\n",
    "                        best_acc_epoch = epoch + 1\n",
    "                        best_val_acc = v_acc\n",
    "                    if v_loss <= best_val_loss:\n",
    "                        torch.save(model.state_dict(), model_name+\".h5\")\n",
    "                        best_val_epoch = epoch + 1\n",
    "                        best_val_loss = v_loss\n",
    "                    #print(f'Epoch[{epoch+1}]: t_loss: {t_loss} t_acc: {t_acc} v_loss: {v_loss} v_acc: {v_acc}')\n",
    "                    print(f'Epoch[{epoch+1}]: v_loss: {v_loss} v_acc: {v_acc}')\n",
    "        \n",
    "        \n",
    "        # Use Validation Set at each epochs to pick the most \n",
    "        if (val_loader and model_name):\n",
    "            model.load_state_dict(torch.load(model_name+\".h5\", map_location='cpu'))\n",
    "            print('Best model saved at epoch: ', best_val_epoch)\n",
    "            print('Best acc model saved at epoch: ', best_acc_epoch)\n",
    "        \n",
    "        # USING TEST SET TO CHECK ACCURACY\n",
    "        #model.eval()\n",
    "        with torch.no_grad():\n",
    "            n_correct = 0\n",
    "            n_samples = 0\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs = inputs.to(model_device)\n",
    "                labels = labels.to(model_device)\n",
    "                   # Forward pass\n",
    "                \n",
    "                # preforward\n",
    "                if calculate_inputs:\n",
    "                    inputs = calculate_inputs(inputs)\n",
    "                outputs = 0 \n",
    "                # forward\n",
    "                if calculate_outputs:\n",
    "                    outputs = calculate_outputs(inputs)\n",
    "                else:\n",
    "                    outputs = model.forward(inputs)\n",
    "                # max returns (value, index)\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                n_samples += labels.size(0)\n",
    "                n_correct += (predicted == labels).sum().item()                \n",
    "            acc = 100.0 * n_correct / n_samples\n",
    "            totalPredictions = n_samples\n",
    "            print(f'Accuracy of the network on the 10000 test images: {acc} %')\n",
    "\n",
    "        \n",
    "    result = {\n",
    "        'correctPredictions': lastCorrect,\n",
    "        'totalPredictions': totalPredictions,\n",
    "        'accuracyThroughEpochs': accuracyHistory,\n",
    "        'numberOfUpdate': numberOfUpdates,\n",
    "    }\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e36e4acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "def print_full_model(model):\n",
    "    assert isinstance(model, nn.Module), \"The model is not a subclass of torch.nn.Module\"\n",
    "    kb = 1000\n",
    "    model_size = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        layer_size = param.nelement() * param.element_size()\n",
    "        model_size += layer_size\n",
    "        print(name,\"\\t\", param.nelement(), \"\\t\", param.element_size(),\"\\t\", layer_size / kb, \"KB\")\n",
    "        \n",
    "    for name, buffer in model.named_buffers():\n",
    "        layer_size = buffer.nelement() * buffer.element_size()\n",
    "        model_size += layer_size\n",
    "        print(name,\"\\t\", layer_size / kb, \"KB\")\n",
    "    print(\"Model Size:\", model_size / kb, \"KB\")\n",
    "\n",
    "def hardThreshold(A: torch.Tensor, sparsity):\n",
    "    '''\n",
    "    Given a Tensor A and the correponding sparsity, returns a copy in the\n",
    "    format of numpy array with the constraint applied\n",
    "    '''\n",
    "    matrix_A = A.data.cpu().detach().numpy().ravel()    \n",
    "    if len(matrix_A) > 0:\n",
    "        threshold = np.percentile(np.abs(matrix_A), (1 - sparsity) * 100.0, method='higher')\n",
    "        matrix_A[np.abs(matrix_A) < threshold] = 0.0\n",
    "    matrix_A = matrix_A.reshape(A.shape)\n",
    "    return matrix_A\n",
    "\n",
    "def get_layers(model):\n",
    "    \"\"\"Recursively get all layers in a PyTorch model.\"\"\"\n",
    "    list_layers = []\n",
    "    # for name, module in model.named_children():\n",
    "    #     # check type of module\n",
    "    #     is_conv1d = isinstance(module, torch.nn.Conv1d)\n",
    "    #     is_conv2d = isinstance(module, torch.nn.Conv2d)\n",
    "    #     is_linear = isinstance(module, torch.nn.Linear)\n",
    "    #     is_sequential = isinstance(module, torch.nn.Sequential)\n",
    "    #     if (is_conv1d or is_conv2d or is_linear):\n",
    "    #         list_layers.append(module)\n",
    "    #     if (is_sequential):\n",
    "    #         for sub_name, sub_module in module.named_children():\n",
    "    #             print(sub_name)\n",
    "    #             # check type of module\n",
    "    #             is_conv1d = isinstance(sub_module, torch.nn.Conv1d)\n",
    "    #             is_conv2d = isinstance(sub_module, torch.nn.Conv2d)\n",
    "    #             is_linear = isinstance(sub_module, torch.nn.Linear)\n",
    "    #             if (is_conv1d or is_conv2d or is_linear):\n",
    "    #                 list_layers.append(sub_module)\n",
    "    for layer in model.children():\n",
    "        if isinstance(layer, nn.Sequential):\n",
    "            # If it's a sequential container, recursively get its layers\n",
    "            list_layers.extend(get_layers(layer))\n",
    "        else:\n",
    "            # If it's a single layer, add it to the list\n",
    "            if (isinstance(layer, torch.nn.Conv1d) or isinstance(layer, torch.nn.Conv2d) or isinstance(layer, torch.nn.Linear)):\n",
    "                list_layers.append(layer)\n",
    "    return list_layers\n",
    "\n",
    "def apply_sparsity(model, list_of_fc_layers, list_of_fc_sparsity, model_device):\n",
    "    assert isinstance(model, nn.Module), \"The model is not a subclass of torch.nn.Module\"\n",
    "    assert len(list_of_fc_layers) == len(list_of_fc_sparsity), \"The lists should be of the same length\"\n",
    "    # asset sparsity between 0 and 1\n",
    "    valid_sparsity = True\n",
    "    for sparsity in list_of_fc_sparsity:\n",
    "        if (sparsity > 1) or (sparsity < 0):\n",
    "            valid_sparsity = False\n",
    "    assert valid_sparsity, \"The sparsity value must be between 0 and 1\"\n",
    "    \n",
    "    list_of_fc_layers = list_of_fc_layers.copy()\n",
    "    list_of_fc_sparsity = list_of_fc_sparsity.copy()\n",
    "    \n",
    "    # apply hardthreshold - in the list we have only layer with require_grad = True\n",
    "    for fc_layer, sparsity in zip(list_of_fc_layers, list_of_fc_sparsity):\n",
    "        layer = fc_layer.weight.data\n",
    "        new_layer = hardThreshold(layer, sparsity)\n",
    "        with torch.no_grad():\n",
    "            fc_layer.weight.data = torch.FloatTensor(new_layer).to(model_device)\n",
    "    \n",
    "def calculate_accuracy(model, train_loader, test_loader, model_device, calculate_inputs=None, calculate_outputs=None):\n",
    "    assert isinstance(model, nn.Module), \"The model is not a subclass of torch.nn.Module\"\n",
    "\n",
    "    acc = 0\n",
    "\n",
    "    # TEST - compute accuracy\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(model_device)\n",
    "            labels = labels.to(model_device)\n",
    "            # preforward\n",
    "            if calculate_inputs:\n",
    "                inputs = calculate_inputs(inputs)\n",
    "            outputs = 0 \n",
    "            # forward\n",
    "            if calculate_outputs:\n",
    "                outputs = calculate_outputs(inputs)\n",
    "            else:\n",
    "                outputs = model.forward(inputs)\n",
    "                    \n",
    "            # max returns (value, index)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        print(f'Accuracy of the network on the train images: {acc} %')\n",
    "\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(model_device)\n",
    "            labels = labels.to(model_device)\n",
    "            # preforward\n",
    "            if calculate_inputs:\n",
    "                inputs = calculate_inputs(inputs)\n",
    "            outputs = 0 \n",
    "            # forward\n",
    "            if calculate_outputs:\n",
    "                outputs = calculate_outputs(inputs)\n",
    "            else:\n",
    "                outputs = model.forward(inputs)\n",
    "            \n",
    "            # max returns (value, index)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        print(f'Accuracy of the network on the 10000 test images: {acc} %')\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3ae4b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sparsity_for_layers(layer_list):\n",
    "    \"\"\"Compute sparsity for each layer in a list of layers.\"\"\"\n",
    "    sparsity_info = []\n",
    "\n",
    "    for layer in layer_list:\n",
    "        weight = layer.data\n",
    "        total_elements = weight.numel()\n",
    "        zero_elements = (weight == 0).sum().item()\n",
    "        sparsity = zero_elements / total_elements\n",
    "        sparsity_info.append((layer.__class__.__name__, sparsity, total_elements, zero_elements))\n",
    "    \n",
    "    # Print the sparsity information for each layer\n",
    "    for layer, sparsity, total_elements, zero_elements in sparsity_info:\n",
    "        print(f'Layer: {layer}, Sparsity: {1-sparsity:.4f}, Total Elements: {total_elements}, Zero Elements: {zero_elements}')\n",
    "\n",
    "    return sparsity_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06b901a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastfeedforward import FFF\n",
    "\n",
    "def train(net, trainloader, epochs, norm_weight=0.0):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    # Define loss and optimizer\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the network for the given number of epochs\n",
    "    for _ in range(epochs):\n",
    "        # Iterate over data\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(net(images), labels)\n",
    "            if norm_weight != 0:\n",
    "                loss += norm_weight * net.fff.w1s.pow(2).sum()\n",
    "                loss += norm_weight * net.fff.w2s.pow(2).sum()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "def test(net, testloader):\n",
    "    \"\"\"Validate the network on the entire test set.\"\"\"\n",
    "    # Define loss and optimizer\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    # Train the network for the given number of epochs\n",
    "    with torch.no_grad():\n",
    "        # Iterate over data\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, input_width, leaf_width, output_width, depth, dropout, region_leak):\n",
    "        super(Net, self).__init__()\n",
    "        self.fff = FFF(input_width, leaf_width, output_width, depth, torch.nn.ReLU(), dropout, train_hardened=True, region_leak=region_leak)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(len(x), -1)\n",
    "        x = self.fff(x)\n",
    "        x = torch.nn.functional.softmax(x, -1)\n",
    "        return x\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.fff.parameters()\n",
    "\n",
    "\n",
    "class FF(torch.nn.Module):\n",
    "    def __init__(self, input_width, layer_width, output_width):\n",
    "        super(FF, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_width, layer_width)\n",
    "        self.fc2 = torch.nn.Linear(layer_width, output_width)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(len(x), -1)\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = torch.nn.functional.softmax(self.fc2(x), -1)\n",
    "        return x\n",
    "\n",
    "    def parameters(self):\n",
    "        return [*self.fc1.parameters(), *self.fc2.parameters()]\n",
    "\n",
    "\n",
    "def compute_n_params(input_width: int, l_w: int, depth: int, output_width: int):\n",
    "    fff = Net(input_width, l_w, output_width, depth, 0, 0)\n",
    "    ff = FF(input_width, l_w, output_width)\n",
    "\n",
    "    n_ff = 0\n",
    "    n_fff = 0\n",
    "    for p in ff.parameters():\n",
    "        n_ff += p.numel()\n",
    "    for i, p in enumerate(fff.parameters()):\n",
    "        print(f\"[{i}-th layer]: {p.shape}\")\n",
    "        n_fff += p.numel()\n",
    "\n",
    "    print(f\"FFF: {n_fff}\\nFF: {n_ff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3e192bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def get_dist(net, testloader):\n",
    "    \"\"\"\n",
    "    Returns the distribution of samples throughout the tree.\n",
    "    \"\"\"\n",
    "\n",
    "    y = []\n",
    "    l = []\n",
    "    with torch.no_grad():\n",
    "        # Iterate over data\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "            outputs, leaves = net.forward(images, return_nodes=True)\n",
    "            y.append(labels)\n",
    "            l.append(leaves)\n",
    "    y = torch.concat(y, 0)\n",
    "    l = torch.concat(l, 0)\n",
    "    return y, l\n",
    "\n",
    "\n",
    "class FFFWrapper(torch.nn.Module):\n",
    "    def __init__(self, fff):\n",
    "        super(FFFWrapper, self).__init__()\n",
    "        self._fff = fff\n",
    "        self._fastinference = [None for i in range(2 ** (self._fff.fff.depth.item()))]\n",
    "\n",
    "    def forward(self, x, return_nodes=False):\n",
    "        \"\"\"\n",
    "        Override the forward method in order to log the data distribution.\n",
    "        \"\"\"\n",
    "        x = x.view(len(x), -1)\n",
    "        original_shape = x.shape\n",
    "        batch_size = x.shape[0]\n",
    "        last_node = torch.zeros(len(x))\n",
    "\n",
    "        current_nodes = torch.zeros((batch_size,), dtype=torch.long, device=x.device)\n",
    "        for i in range(self._fff.fff.depth.item()):\n",
    "            plane_coeffs = self._fff.fff.node_weights.index_select(dim=0, index=current_nodes)\n",
    "            plane_offsets = self._fff.fff.node_biases.index_select(dim=0, index=current_nodes)\n",
    "            plane_coeff_score = torch.bmm(x.unsqueeze(1), plane_coeffs.unsqueeze(-1))\n",
    "            plane_score = plane_coeff_score.squeeze(-1) + plane_offsets\n",
    "            plane_choices = (plane_score.squeeze(-1) >= 0).long()\n",
    "\n",
    "            platform = torch.tensor(2 ** i - 1, dtype=torch.long, device=x.device)\n",
    "            next_platform = torch.tensor(2 ** (i+1) - 1, dtype=torch.long, device=x.device)\n",
    "            current_nodes = (current_nodes - platform) * 2 + plane_choices + next_platform\n",
    "\n",
    "        leaves = current_nodes - next_platform\n",
    "        new_logits = torch.empty((batch_size, self._fff.fff.output_width), dtype=torch.float, device=x.device)\n",
    "        last_node = leaves\n",
    "\n",
    "        for i in range(leaves.shape[0]):\n",
    "            leaf_index = leaves[i]\n",
    "            if self._fastinference[leaf_index] is not None:\n",
    "                new_logits[i] = self._fastinference[leaf_index]\n",
    "            else:\n",
    "                logits = torch.matmul( x[i].unsqueeze(0), self._fff.fff.w1s[leaf_index])\n",
    "                logits += self._fff.fff.b1s[leaf_index].unsqueeze(-2)\n",
    "                activations = self._fff.fff.activation(logits)\n",
    "                new_logits[i] = torch.matmul( activations, self._fff.fff.w2s[leaf_index]).squeeze(-2)\n",
    "\n",
    "        if return_nodes:\n",
    "            return new_logits.view(*original_shape[:-1], self._fff.fff.output_width), last_node\n",
    "        return new_logits.view(*original_shape[:-1], self._fff.fff.output_width)\n",
    "\n",
    "\n",
    "    def simplify_leaves(self, trainloader):\n",
    "        y, leaves = (get_dist(self, trainloader))\n",
    "        y = y.cpu().detach().numpy()\n",
    "        outputs = y.max() + 1\n",
    "        leaves = leaves.cpu().detach().numpy()\n",
    "\n",
    "        n_simplifications = 0\n",
    "        ratios = {}\n",
    "        for l in np.unique(leaves):\n",
    "            ratios[l] = torch.zeros(outputs)\n",
    "            indices = leaves == l\n",
    "\n",
    "            for i in range(outputs):\n",
    "                ratios[l][i] = (np.sum(y[indices] == i) / np.sum(indices))\n",
    "\n",
    "            argmax = np.argmax(ratios[l])\n",
    "            if ratios[l][argmax] > 0.7:\n",
    "                output = torch.zeros(outputs)\n",
    "                output[argmax] = 1\n",
    "                self._fastinference[l] = output\n",
    "                n_simplifications += 1\n",
    "                print(f\"Leaf {l} has been replaced with {argmax}\")\n",
    "        print(self._fastinference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fee5d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFFWrapper(torch.nn.Module):\n",
    "    def __init__(self, fff):\n",
    "        super(FFFWrapper, self).__init__()\n",
    "        self._fff = fff\n",
    "        self._fastinference = [None for i in range(2 ** (self._fff.fff.depth.item()))]\n",
    "\n",
    "    def forward(self, x, return_nodes=False):\n",
    "        \"\"\"\n",
    "        Override the forward method in order to log the data distribution.\n",
    "        \"\"\"\n",
    "        x = x.view(len(x), -1)\n",
    "        original_shape = x.shape\n",
    "        batch_size = x.shape[0]\n",
    "        last_node = torch.zeros(len(x))\n",
    "\n",
    "        current_nodes = torch.zeros((batch_size,), dtype=torch.long, device=x.device)\n",
    "        for i in range(self._fff.fff.depth.item()):\n",
    "            plane_coeffs = self._fff.fff.node_weights.index_select(dim=0, index=current_nodes)\n",
    "            plane_offsets = self._fff.fff.node_biases.index_select(dim=0, index=current_nodes)\n",
    "            plane_coeff_score = torch.bmm(x.unsqueeze(1), plane_coeffs.unsqueeze(-1))\n",
    "            plane_score = plane_coeff_score.squeeze(-1) + plane_offsets\n",
    "            plane_choices = (plane_score.squeeze(-1) >= 0).long()\n",
    "\n",
    "            platform = torch.tensor(2 ** i - 1, dtype=torch.long, device=x.device)\n",
    "            next_platform = torch.tensor(2 ** (i+1) - 1, dtype=torch.long, device=x.device)\n",
    "            current_nodes = (current_nodes - platform) * 2 + plane_choices + next_platform\n",
    "\n",
    "        leaves = current_nodes - next_platform\n",
    "        new_logits = torch.empty((batch_size, self._fff.fff.output_width), dtype=torch.float, device=x.device)\n",
    "        last_node = leaves\n",
    "\n",
    "        for i in range(leaves.shape[0]):\n",
    "            leaf_index = leaves[i]\n",
    "            if self._fastinference[leaf_index] is not None:\n",
    "                new_logits[i] = self._fastinference[leaf_index]\n",
    "            else:\n",
    "                logits = torch.matmul( x[i].unsqueeze(0), self._fff.fff.w1s[leaf_index])\n",
    "                logits += self._fff.fff.b1s[leaf_index].unsqueeze(-2)\n",
    "                activations = self._fff.fff.activation(logits)\n",
    "                new_logits[i] = torch.matmul( activations, self._fff.fff.w2s[leaf_index]).squeeze(-2)\n",
    "\n",
    "        if return_nodes:\n",
    "            return new_logits.view(*original_shape[:-1], self._fff.fff.output_width), last_node\n",
    "        return new_logits.view(*original_shape[:-1], self._fff.fff.output_width)\n",
    "\n",
    "\n",
    "    def simplify_leaves(self, trainloader):\n",
    "        y, leaves = (get_dist(self, trainloader))\n",
    "        y = y.cpu().detach().numpy()\n",
    "        outputs = y.max() + 1\n",
    "        leaves = leaves.cpu().detach().numpy()\n",
    "\n",
    "        n_simplifications = 0\n",
    "        ratios = {}\n",
    "        for l in np.unique(leaves):\n",
    "            ratios[l] = torch.zeros(outputs)\n",
    "            indices = leaves == l\n",
    "\n",
    "            for i in range(outputs):\n",
    "                ratios[l][i] = (np.sum(y[indices] == i) / np.sum(indices))\n",
    "\n",
    "            argmax = np.argmax(ratios[l])\n",
    "            if ratios[l][argmax] >= 0:\n",
    "                output = torch.zeros(outputs)\n",
    "                output[argmax] = 1\n",
    "                self._fastinference[l] = output\n",
    "                n_simplifications += 1\n",
    "                print(f\"Leaf {l} has been replaced with {argmax}\")\n",
    "        print(self._fastinference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3d7faec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typer\n",
    "import mlflow\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_split_code(array, bias):\n",
    "    code = \"\"\"\n",
    "    acc = \"\"\" + \" + \".join(f\"x[{i}] * {v}\" for i, v in enumerate(array)) + \"\"\";\n",
    "    acc += \"\"\" + str(bias[0]) + \"\"\";\n",
    "    \"\"\"\n",
    "    return code\n",
    "\n",
    "\n",
    "def get_output_code(w1, b1, w2, b2):\n",
    "    code = \"\"\"\n",
    "    float hidden[\"\"\" + str(w1.shape[1]) + \"\"\"];\n",
    "    \"\"\"\n",
    "    for i in range(w1.shape[1]):\n",
    "        code += f\"hidden[{i}] = {b1[i]} + \" + \" + \".join(f\"x[{j}] * {v}\" for j, v in enumerate(w1[:, i])) + \";\\n\"\n",
    "        code += f\"hidden[{i}] = hidden[{i}] > 0 ? hidden[{i}] : 0;\\n\"\n",
    "    code += \"\"\"\n",
    "    float logits[\"\"\" + str(w2.shape[1]) + \"\"\"];\n",
    "    \"\"\"\n",
    "    for j in range(w2.shape[1]):\n",
    "        code += f\"logits[{j}] = {b2[j]} + \" + \" + \".join(f\"hidden[{i}] * {v}\" for i, v in enumerate(w2[:, j])) + \";\\n\"\n",
    "        code += f\"logits[{j}] = logits[{j}] > 0 ? logits[{j}] : 0;\\n\"\n",
    "\n",
    "    code += \"\"\"\n",
    "    max = 0.0;\n",
    "    argmax = 0;\n",
    "    for (int i = 0; i < \"\"\" + str(w2.shape[1]) + \"\"\"; i++) {\n",
    "        if (logits[i] > max) {\n",
    "            max = logits[i];\n",
    "            argmax = i;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return argmax;\n",
    "    \"\"\"\n",
    "\n",
    "    return code\n",
    "\n",
    "def get_splits(weights, biases):\n",
    "    code = \"\"\"int perform_inference(float* x) {\n",
    "    float acc;\n",
    "    float max;\n",
    "    int argmax;\n",
    "        <replaceme>\n",
    "}\"\"\"\n",
    "    for index, (array, bias) in enumerate(zip(weights, biases)):\n",
    "        code = code.replace(\"<replaceme>\", get_split_code(array, bias), 1)\n",
    "    return code\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, array, bias, left, right):\n",
    "        self._array = array\n",
    "        self._bias = bias\n",
    "        self._left = left\n",
    "        self._right = right\n",
    "\n",
    "    def __str__(self):\n",
    "        code = get_split_code(self._array, self._bias)\n",
    "\n",
    "        code += \"\"\"\n",
    "        if (acc >= 0) {\n",
    "            \"\"\" + str(self._left) + \"\"\"\n",
    "        } else {\n",
    "            \"\"\" + str(self._right) + \"\"\"\n",
    "        }\n",
    "        \"\"\"\n",
    "        return code\n",
    "\n",
    "\n",
    "class Leaf(Node):\n",
    "    def __init__(self, w1, b1, w2, b2):\n",
    "        self._w1 = w1\n",
    "        self._b1 = b1\n",
    "        self._w2 = w2\n",
    "        self._b2 = b2\n",
    "\n",
    "    def __str__(self):\n",
    "        if self._w2 is None:\n",
    "            return f\"return {self._w1};\\n\"\n",
    "        return get_output_code(self._w1, self._b1, self._w2, self._b2)\n",
    "\n",
    "def print_parameters(params, key, lines, line, flit, skipTruncatedLeaves, sizes_print=False, index_print=True):\n",
    "    # the first check on the sparsity on the weight also consider the non zero values of truncated leaves\n",
    "    \n",
    "    weight = params[key]\n",
    "    dim = len(weight.shape)\n",
    "    \n",
    "    non_zero_values = np.count_nonzero(weight)\n",
    "    first_dim = weight.shape[0]\n",
    "    sparse = False\n",
    "    \n",
    "    if (dim == 2):\n",
    "        weight_row = weight.shape[0]\n",
    "        weight_col = weight.shape[1]\n",
    "        \n",
    "        sparse = non_zero_values < ((weight_row * (weight_col - 1) - 1) / 2)\n",
    "    elif (dim == 3):\n",
    "        weight_depth = weight.shape[0]\n",
    "        weight_row = weight.shape[1]\n",
    "        weight_col = weight.shape[2]\n",
    "        \n",
    "        size_requested = weight_depth * weight_row * weight_col\n",
    "        sparse = non_zero_values < ((size_requested - weight_depth) / 2)\n",
    "    if (not sparse):\n",
    "        # print the parameters as usal\n",
    "        lines.insert(\n",
    "            line,\n",
    "            \"#define \" + key + \"_SPARSE \" + str(0) + \"\\n\"\n",
    "        )\n",
    "        line += 1\n",
    "        line += 1\n",
    "        \n",
    "        param = weight\n",
    "        if (key in ['LEAF_HIDDEN_WEIGHTS', 'LEAF_HIDDEN_BIASES', 'LEAF_OUTPUT_WEIGHTS', 'LEAF_OUTPUT_BIASES']):\n",
    "            if (skipTruncatedLeaves):\n",
    "                param = param[params['FASTINFERENCE'] == -1]\n",
    "        param = param.flatten()\n",
    "        tmp = \"\"\n",
    "        if (flit and key not in ['FASTINFERENCE']):\n",
    "            tmp = \", \".join([\"F_LIT(\" + str(x) + \")\" for x in param])\n",
    "        else:\n",
    "            tmp = \", \".join([str(x) for x in param])\n",
    "        lines.insert(\n",
    "            line,\n",
    "            tmp\n",
    "        )\n",
    "    else:\n",
    "        # CSC or CSR format\n",
    "        leaves_values = np.empty([0], dtype=float)\n",
    "        leaves_offsets = np.empty([0], dtype=int)\n",
    "        leaves_sizes = None\n",
    "        printed_dim = key + \"_DIM_1\"\n",
    "        if (sizes_print):\n",
    "            leaves_sizes = np.empty([first_dim], dtype=int)\n",
    "        elif(index_print):\n",
    "            leaves_sizes = np.zeros([1], dtype=int)\n",
    "            printed_dim += \" + 1\"\n",
    "            \n",
    "        value_position = 0\n",
    "        actual_non_zero_values = 0\n",
    "        \n",
    "        for index, leaf_weight in enumerate(weight): # from 0 to first_dim\n",
    "            \n",
    "            if (key in ['LEAF_HIDDEN_WEIGHTS', 'LEAF_HIDDEN_BIASES', 'LEAF_OUTPUT_WEIGHTS', 'LEAF_OUTPUT_BIASES']):\n",
    "                # insert filters non zero values into the fitler sizes\n",
    "                if (params['FASTINFERENCE'][index] != -1 and skipTruncatedLeaves):\n",
    "                    leaves_sizes[index] = 0\n",
    "                    continue\n",
    "            \n",
    "            # insert filters non zero values into the fitler sizes\n",
    "            non_zero_values_here = np.count_nonzero(leaf_weight)\n",
    "            actual_non_zero_values += non_zero_values_here\n",
    "            # flatten the filter\n",
    "            flatten_leaf = leaf_weight.ravel()\n",
    "            offset = 1\n",
    "            \n",
    "            if (sizes_print):\n",
    "                # _sizes[DIM_1] = for each node/leaf we save the number of NNZ contained\n",
    "                leaves_sizes[index] = non_zero_values_here\n",
    "            elif (index_print):\n",
    "                # _sizes[DIM_1 + 1] = for each node/leaf we save the index in _data array of the starting value\n",
    "                # _sizes from {0 up to NNZ}\n",
    "                leaves_sizes = np.append(leaves_sizes, actual_non_zero_values)\n",
    "            \n",
    "            for value in flatten_leaf: # from 0 to (n_depth * n_height * n_width)\n",
    "                if (value == 0):\n",
    "                    # increase offset\n",
    "                    offset += 1\n",
    "                else:\n",
    "                    # save value, save index, reset offset, increase position\n",
    "                    leaves_values = np.append(leaves_values, value)\n",
    "                    leaves_offsets = np.append(leaves_offsets, offset)\n",
    "                    leaves_values[value_position] = value\n",
    "                    leaves_offsets[value_position] = offset\n",
    "                    offset = 1\n",
    "                    value_position += 1\n",
    "                \n",
    "            \n",
    "        tmp = \"\"\n",
    "        # substitute the definition\n",
    "        lines[line] = \"#define \" + key + \"_NNZ \" + str(actual_non_zero_values) + \"\\n\"\n",
    "        line+=1\n",
    "        lines.insert(\n",
    "            line,\n",
    "            \"#define \" + key + \"_DIM \" + str(dim) + \"\\n\"\n",
    "        )\n",
    "        line+=1\n",
    "        lines.insert(\n",
    "            line,\n",
    "            \"#define \" + key + \"_SPARSE \" + str(1) + \"\\n\"\n",
    "        )\n",
    "        for d in range(0, dim):\n",
    "            line+=1\n",
    "            lines.insert(\n",
    "                line,\n",
    "                \"#define \" + key + \"_DIM_\" + str(d + 1) + \" \" + str(weight.shape[d]) + \"\\n\"\n",
    "            )\n",
    "        line+=1\n",
    "        lines.insert(\n",
    "            line,\n",
    "            \"__hifram fixed \" + key + \"_data[\" + key + \"_NNZ] = {\\n\"\n",
    "        )\n",
    "        line+=1\n",
    "        \n",
    "        if flit:\n",
    "            tmp = \", \".join([\"F_LIT(\" + str(x) + \")\" for x in leaves_values])\n",
    "        else:\n",
    "            tmp = \", \".join([str(x) for x in leaves_values])\n",
    "        lines.insert(\n",
    "            line,\n",
    "            tmp\n",
    "        )\n",
    "        line+=1\n",
    "        line+=1\n",
    "        line+=1\n",
    "        lines.insert(\n",
    "            line,\n",
    "            \"\\n__hifram fixed \" + key + \"_offset[\" + key + \"_NNZ] = {\\n\"\n",
    "        )\n",
    "        line+=1\n",
    "        if (flit and False):\n",
    "            tmp = \", \".join([\"F_LIT(\" + str(x) + \")\" for x in leaves_offsets])\n",
    "        else:\n",
    "            tmp = \", \".join([str(x) for x in leaves_offsets])\n",
    "        lines.insert(\n",
    "            line,\n",
    "            tmp\n",
    "        )\n",
    "        line+=1\n",
    "        lines.insert(\n",
    "            line,\n",
    "            \"\\n\"\n",
    "        )\n",
    "        line+=1\n",
    "        lines.insert(\n",
    "            line,\n",
    "            \"};\\n\"\n",
    "        )\n",
    "        line+=1\n",
    "        lines.insert(\n",
    "            line,\n",
    "            \"\\n__hifram fixed \" + key + \"_sizes[\" + printed_dim + \"] = {\\n\"\n",
    "        )\n",
    "        line+=1\n",
    "        if (flit and False):\n",
    "            tmp = \", \".join([\"F_LIT(\" + str(x) + \")\" for x in leaves_sizes])\n",
    "        else:\n",
    "            tmp = \", \".join([str(x) for x in leaves_sizes])\n",
    "        lines.insert(\n",
    "            line,\n",
    "            tmp\n",
    "        )\n",
    "        line+=1\n",
    "        lines.insert(\n",
    "            line,\n",
    "            \"\\n\"\n",
    "        )\n",
    "        line+=1\n",
    "        lines.insert(\n",
    "            line,\n",
    "            \"};\\n\\n\"\n",
    "        )\n",
    "    \n",
    "def make_program(wrapped_model, name, original_fastinference, flit=True, skipTruncatedLeaves=False):\n",
    "\n",
    "    node_weights = wrapped_model._fff.fff.node_weights.cpu().detach().numpy()\n",
    "    node_biases = wrapped_model._fff.fff.node_biases.cpu().detach().numpy()\n",
    "    w1s = wrapped_model._fff.fff.w1s\n",
    "    b1s = wrapped_model._fff.fff.b1s.cpu().detach().numpy()\n",
    "    w2s = wrapped_model._fff.fff.w2s\n",
    "    b2s = wrapped_model._fff.fff.b2s.cpu().detach().numpy()\n",
    "    fastinference = wrapped_model._fastinference\n",
    "\n",
    "    w1s = w1s.transpose(1, 2).cpu().detach().numpy()\n",
    "    w2s = w2s.transpose(1, 2).cpu().detach().numpy()\n",
    "\n",
    "    params = {}\n",
    "\n",
    "    params['NODE_WEIGHTS'] = node_weights#.flatten()\n",
    "    params['NODE_BIASES'] = node_biases#.flatten()\n",
    "    params['FASTINFERENCE'] = np.array([-1 if x is None else int(x.argmax()) for x in fastinference])\n",
    "    actual_leaves_weights = w1s #[params['FASTINFERENCE'] == -1]\n",
    "    actual_leaves_biases = b1s #[params['FASTINFERENCE'] == -1]\n",
    "    actual_leaves_out_weights = w2s #[params['FASTINFERENCE'] == -1]\n",
    "    actual_leaves_out_biases = b2s #[params['FASTINFERENCE'] == -1]\n",
    "    params['LEAF_HIDDEN_WEIGHTS'] = actual_leaves_weights#.flatten()\n",
    "    params['LEAF_HIDDEN_BIASES'] = actual_leaves_biases#.flatten()\n",
    "    params['LEAF_OUTPUT_WEIGHTS'] = actual_leaves_out_weights#.flatten()\n",
    "    params['LEAF_OUTPUT_BIASES'] = actual_leaves_out_biases#.flatten()\n",
    "    with open(\"weights_\" + name + \".h\", \"w\") as f:\n",
    "        with open(\"weights_template.h\") as in_f:\n",
    "            lines = in_f.readlines()\n",
    "\n",
    "            i = 0\n",
    "            while i < len(lines):\n",
    "                i += 1\n",
    "                if \"Add definitions here\" in lines[i]:\n",
    "                    break\n",
    "            lines[i] = (f\"\"\"// name of the model  {name}\n",
    "\n",
    "#define DEPTH {wrapped_model._fff.fff.depth.item()}\n",
    "#define N_LEAVES {2 ** wrapped_model._fff.fff.depth.item()}\n",
    "#define INPUT_SIZE {wrapped_model._fff.fff.input_width}\n",
    "#define LEAF_WIDTH {wrapped_model._fff.fff.leaf_width}\n",
    "#define OUTPUT_SIZE {wrapped_model._fff.fff.output_width}\n",
    "#define SIMPLIFIED_LEAVES {sum([f is not None for f in fastinference])}\n",
    "#define ORIGINAL_FASTINFERENCE {original_fastinference}\"\"\")\n",
    "            i+=1\n",
    "            lines.insert(i, \"\\n\")\n",
    "\n",
    "            # lines.insert(i+7, \"\"\"\n",
    "# float FASTINFERENCE[N_LEAVES] = {-1};\n",
    "# float NODE_WEIGHTS[N_LEAVES-1][INPUT_SIZE];\n",
    "# float NODE_BIASES[N_LEAVES-1];\n",
    "# float LEAF_HIDDEN_WEIGHTS[N_LEAVES-SIMPLIFIED_LEAVES][LEAF_WIDTH][INPUT_SIZE];\n",
    "# float LEAF_OUTPUT_WEIGHTS[N_LEAVES-SIMPLIFIED_LEAVES][OUTPUT_SIZE][LEAF_WIDTH];\n",
    "# float LEAF_HIDDEN_BIASES[N_LEAVES-SIMPLIFIED_LEAVES][LEAF_WIDTH];\n",
    "# float LEAF_OUTPUT_BIASES[N_LEAVES-SIMPLIFIED_LEAVES][OUTPUT_SIZE];\n",
    "            # \"\"\")\n",
    "\n",
    "            for key in params.keys():\n",
    "                i = 0\n",
    "                while i < len(lines):\n",
    "                    if f\"fixed {key}\" in lines[i]:\n",
    "                        break\n",
    "                    i += 1\n",
    "#                 i += 1\n",
    "                # line of the definition of the parameter\n",
    "                # calculate sparsity and choose representation\n",
    "                # if dense keep the definition, i+=1, and print\n",
    "                # if sparse\n",
    "                print_parameters(params, key, lines, i, flit, skipTruncatedLeaves)\n",
    "                # print Parameters\n",
    "                \n",
    "                # calculate sparsity and choose representation\n",
    "                # if dense -> print as we already are doing\n",
    "                # if not change the representation\n",
    "                \n",
    "\n",
    "            f.writelines(lines)\n",
    "    return wrapped_model\n",
    "\n",
    "\n",
    "def main(run_id, name, original_fastinference):\n",
    "#     import torch\n",
    "    net = make_program(run_id, name, original_fastinference)\n",
    "#     net._fff.eval()\n",
    "#     X = np.loadtxt('test.txt')\n",
    "#     X = torch.Tensor(X)\n",
    "#     with open('ref_outputs.txt', 'w') as f:\n",
    "#         y = net(X).argmax(1)\n",
    "#         y = [(str(x) + \"\\n\") for x in y.detach().cpu().numpy()]\n",
    "#         f.writelines(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94b9bfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trainset': 60000, 'testset': 10000}\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\"\"\"Load CIFAR-10 (training and test set).\"\"\"\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ]\n",
    ")\n",
    "trainset = MNIST(\"../data\", train=True,  download=True, transform=transform)\n",
    "testset = MNIST(\"../data\",  train=False, download=True, transform=transform)\n",
    "\n",
    "# Select class to keep \n",
    "trainloader = DataLoader(trainset, batch_size=1024, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=1024)\n",
    "\n",
    "num_examples = {\"trainset\" : len(trainset), \"testset\" : len(testset)}\n",
    "\n",
    "print(num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c57c37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_run = [\n",
    "'543fe9acb34441a3a82b09ca2ef6046c',\n",
    "'4ea2391b3d014e2fafff3accfb352d2c',\n",
    "'612d1573468c4ffaa89bf54d60ce4508',\n",
    "'24879e69bd174ef6a9973359ea1b9b6c',\n",
    "'7c66090a514e4080b639b6f261d5a134',\n",
    "'a258b245549043ef84a9beff50896872',\n",
    "'57f3c5cd82dc480c94e516ab34620331',\n",
    "'cef7d9cd3ea548b783a400984a7145fc',\n",
    "'706ca101f6a2446db81d58abdf6e2815',\n",
    "'2a116553f512425a9409bd968b9fe8ef',\n",
    "'90b23d76307e425ea4ba7d647c7cb7f6',\n",
    "'57e917cd181c456bbf3c365b5018a2d6',\n",
    "'715fba635c6145b185c29e6aa6b6bcbf',\n",
    "'652dc0e8fe0042309b990da5fc377d60',\n",
    "'580862314acb40cbb6411391f6def1e1',\n",
    "'0c4b701ba2c2434b99a83f0b771b3945',\n",
    "'755af7caf9e74fbdbc2dee292dd8b3d1',\n",
    "'e6c2200cd3a942b081e77a4fcbb21df6',\n",
    "'9ac931f6215644bf9d22e6fcfc7f179f',\n",
    "'69d271a25d744404ad63c43b575192a6',\n",
    "'27f4eafb191340f592dfab6992d3700d',\n",
    "'9d555e630619470c8e4a6d075ba0e65f',\n",
    "'89e999f7bcce4b238cd3bca960ec27da',\n",
    "'15d383cd1c044c8cb7cf5b5de6955b13',\n",
    "]\n",
    "\n",
    "# mlflow.artifacts.download_artifacts(run_id=run_id, dst_path=\".\")\n",
    "# wrapped_model = pickle.load(open(\"./truncated_model.pkl\", \"rb\"))\n",
    "# wrapped_model._fff.fff.depth.item()\n",
    "# wrapped_model._fff.fff.input_width\n",
    "# wrapped_model._fff.fff.leaf_width\n",
    "# wrapped_model._fff.fff.output_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42dc558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training variable\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "learning_rate = 0.001\n",
    "num_epochs = 7\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Dataset\n",
    "batch_size = 1024\n",
    "val_size = 5000\n",
    "train_size = len(trainset) - val_size\n",
    "train_ds, val_ds = random_split(trainset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_ds, batch_size, num_workers=4)\n",
    "test_loader = DataLoader(testset, batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc7c9ea1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f94096e529914150a31074177e057caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\t 543fe9acb34441a3a82b09ca2ef6046c\n",
      "Depth:\t 4\n",
      "Input:\t 784\n",
      "Output:\t 10\n",
      "Leaf:\t 32\n",
      "Buffer:\t 90\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5530f516402f416da068fcf9b3c77f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\t 4ea2391b3d014e2fafff3accfb352d2c\n",
      "Depth:\t 4\n",
      "Input:\t 784\n",
      "Output:\t 10\n",
      "Leaf:\t 32\n",
      "Buffer:\t 90\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d394a458fa8446c9ce9613f250ce726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\t 612d1573468c4ffaa89bf54d60ce4508\n",
      "Depth:\t 3\n",
      "Input:\t 784\n",
      "Output:\t 10\n",
      "Leaf:\t 32\n",
      "Buffer:\t 90\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1708c87293394235a2272a9d2028a777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\t 24879e69bd174ef6a9973359ea1b9b6c\n",
      "Depth:\t 3\n",
      "Input:\t 784\n",
      "Output:\t 10\n",
      "Leaf:\t 32\n",
      "Buffer:\t 90\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99b1acd559a4f1f942e424590a328bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\t 7c66090a514e4080b639b6f261d5a134\n",
      "Depth:\t 2\n",
      "Input:\t 784\n",
      "Output:\t 10\n",
      "Leaf:\t 32\n",
      "Buffer:\t 90\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c77c9629d2454a915512f45be2d68e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\t a258b245549043ef84a9beff50896872\n",
      "Depth:\t 2\n",
      "Input:\t 784\n",
      "Output:\t 10\n",
      "Leaf:\t 32\n",
      "Buffer:\t 90\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc028a0aae4483ea89cf0dc8835a261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\t 57f3c5cd82dc480c94e516ab34620331\n",
      "Depth:\t 4\n",
      "Input:\t 784\n",
      "Output:\t 10\n",
      "Leaf:\t 16\n",
      "Buffer:\t 58\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6570f454935748439afa677e65e741ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\t cef7d9cd3ea548b783a400984a7145fc\n",
      "Depth:\t 4\n",
      "Input:\t 784\n",
      "Output:\t 10\n",
      "Leaf:\t 16\n",
      "Buffer:\t 58\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db13baef52634228b91abf67497d7595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\t 706ca101f6a2446db81d58abdf6e2815\n",
      "Depth:\t 3\n",
      "Input:\t 784\n",
      "Output:\t 10\n",
      "Leaf:\t 16\n",
      "Buffer:\t 58\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d0062298d24bfa954d03c1f88344cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\t 2a116553f512425a9409bd968b9fe8ef\n",
      "Depth:\t 3\n",
      "Input:\t 784\n",
      "Output:\t 10\n",
      "Leaf:\t 16\n",
      "Buffer:\t 58\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9945d67dc781463cac2016e572b20ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\t 90b23d76307e425ea4ba7d647c7cb7f6\n",
      "Depth:\t 2\n",
      "Input:\t 784\n",
      "Output:\t 10\n",
      "Leaf:\t 16\n",
      "Buffer:\t 58\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "530b34bf2d684b68b969fd690d6d4c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\t 57e917cd181c456bbf3c365b5018a2d6\n",
      "Depth:\t 2\n",
      "Input:\t 784\n",
      "Output:\t 10\n",
      "Leaf:\t 16\n",
      "Buffer:\t 58\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd82bc3fffaa4727827beb7deeb7d587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\t 715fba635c6145b185c29e6aa6b6bcbf\n",
      "Depth:\t 4\n",
      "Input:\t 784\n",
      "Output:\t 10\n",
      "Leaf:\t 8\n",
      "Buffer:\t 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "755feebbd479450d81f2374c0f6728dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\t 652dc0e8fe0042309b990da5fc377d60\n",
      "Depth:\t 4\n",
      "Input:\t 784\n",
      "Output:\t 10\n",
      "Leaf:\t 8\n",
      "Buffer:\t 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3e74fd1c9946a0a2bf7f7ee42c0139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\t 580862314acb40cbb6411391f6def1e1\n",
      "Depth:\t 3\n",
      "Input:\t 784\n",
      "Output:\t 10\n",
      "Leaf:\t 8\n",
      "Buffer:\t 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd2ea7628faf42efa28e1873c4bc5bb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\t 0c4b701ba2c2434b99a83f0b771b3945\n",
      "Depth:\t 3\n",
      "Input:\t 784\n",
      "Output:\t 10\n",
      "Leaf:\t 8\n",
      "Buffer:\t 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d11d2dee1a445e0a36909f4eca302f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\t 755af7caf9e74fbdbc2dee292dd8b3d1\n",
      "Depth:\t 2\n",
      "Input:\t 784\n",
      "Output:\t 10\n",
      "Leaf:\t 8\n",
      "Buffer:\t 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a80f19e7b747c1944f0521f601b780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\t e6c2200cd3a942b081e77a4fcbb21df6\n",
      "Depth:\t 2\n",
      "Input:\t 784\n",
      "Output:\t 10\n",
      "Leaf:\t 8\n",
      "Buffer:\t 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "187e186a962e4ae08cc23089cd39f5b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\t 9ac931f6215644bf9d22e6fcfc7f179f\n",
      "Depth:\t 4\n",
      "Input:\t 784\n",
      "Output:\t 10\n",
      "Leaf:\t 4\n",
      "Buffer:\t 34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b3c22e1efd43fd8f75ff7704fc96db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\t 69d271a25d744404ad63c43b575192a6\n",
      "Depth:\t 4\n",
      "Input:\t 784\n",
      "Output:\t 10\n",
      "Leaf:\t 4\n",
      "Buffer:\t 34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "598398e347a94b31b21f7caed496469f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\t 27f4eafb191340f592dfab6992d3700d\n",
      "Depth:\t 3\n",
      "Input:\t 784\n",
      "Output:\t 10\n",
      "Leaf:\t 4\n",
      "Buffer:\t 34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "379d9d3cb3514b6988890a15aa429e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\t 9d555e630619470c8e4a6d075ba0e65f\n",
      "Depth:\t 3\n",
      "Input:\t 784\n",
      "Output:\t 10\n",
      "Leaf:\t 4\n",
      "Buffer:\t 34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4891796f49c841219c9d47bb2f9d802e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\t 89e999f7bcce4b238cd3bca960ec27da\n",
      "Depth:\t 2\n",
      "Input:\t 784\n",
      "Output:\t 10\n",
      "Leaf:\t 4\n",
      "Buffer:\t 34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "841b43fd5b404fb4be82c5c628e17304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\t 15d383cd1c044c8cb7cf5b5de6955b13\n",
      "Depth:\t 2\n",
      "Input:\t 784\n",
      "Output:\t 10\n",
      "Leaf:\t 4\n",
      "Buffer:\t 34\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for i in range (0,len(list_of_run)):\n",
    "    run_id = list_of_run[i]\n",
    "    mlflow.artifacts.download_artifacts(run_id=run_id, dst_path=\"./baselines\")\n",
    "    wrapped_model = pickle.load(open(\"./baselines/truncated_model.pkl\", \"rb\"))\n",
    "    depth = wrapped_model._fff.fff.depth.item()\n",
    "    input_width = wrapped_model._fff.fff.input_width\n",
    "    leaf_width = wrapped_model._fff.fff.leaf_width\n",
    "    output_width = wrapped_model._fff.fff.output_width\n",
    "    buffer_size = 2*(leaf_width + output_width + 3)\n",
    "    print(\"Run:\\t\", run_id)\n",
    "    print(\"Depth:\\t\", depth)\n",
    "    print(\"Input:\\t\", input_width)\n",
    "    print(\"Output:\\t\", output_width)\n",
    "    print(\"Leaf:\\t\", leaf_width)\n",
    "    print(\"Buffer:\\t\", buffer_size)\n",
    "    \n",
    "    # to reduce the sparsity and train only below a certain tresholds\n",
    "    list_of_sizes = [100, 90, 80, 70, 60, 50]\n",
    "    checked_sizes = [False for x in list_of_sizes]\n",
    "    current_size_index = 0\n",
    "    \n",
    "    start = 0.5\n",
    "    a = start\n",
    "    b = start\n",
    "    sizes=[]\n",
    "    before_trunc_sizes=[]\n",
    "    trunc_sizes=[]\n",
    "\n",
    "    model = wrapped_model.to(device)\n",
    "    \n",
    "    layers_list = []\n",
    "    for i, (name, p) in enumerate(model.named_parameters()):\n",
    "        if (len(list(p.shape)) > 1 and p.requires_grad):\n",
    "            layers_list.append(p)\n",
    "    un, comp, layers = print_size_fc(model, layers_list, [1,1,1,1,1,1])\n",
    "    \n",
    "    result.append({'run_id': run_id, 'depth': depth,'input_width':input_width, \n",
    "                   'output': output_width, 'leaf_width':leaf_width,\n",
    "                   'buffer_size': buffer_size, 'sizes': un})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5777cceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'run_id': '543fe9acb34441a3a82b09ca2ef6046c', 'depth': 4, 'input_width': 784, 'output': 10, 'leaf_width': 32, 'buffer_size': 90, 'sizes': 1675908}\n",
      "{'run_id': '4ea2391b3d014e2fafff3accfb352d2c', 'depth': 4, 'input_width': 784, 'output': 10, 'leaf_width': 32, 'buffer_size': 90, 'sizes': 1675908}\n",
      "{'run_id': '612d1573468c4ffaa89bf54d60ce4508', 'depth': 3, 'input_width': 784, 'output': 10, 'leaf_width': 32, 'buffer_size': 90, 'sizes': 836388}\n",
      "{'run_id': '24879e69bd174ef6a9973359ea1b9b6c', 'depth': 3, 'input_width': 784, 'output': 10, 'leaf_width': 32, 'buffer_size': 90, 'sizes': 836388}\n",
      "{'run_id': '7c66090a514e4080b639b6f261d5a134', 'depth': 2, 'input_width': 784, 'output': 10, 'leaf_width': 32, 'buffer_size': 90, 'sizes': 416628}\n",
      "{'run_id': 'a258b245549043ef84a9beff50896872', 'depth': 2, 'input_width': 784, 'output': 10, 'leaf_width': 32, 'buffer_size': 90, 'sizes': 416628}\n",
      "{'run_id': '57f3c5cd82dc480c94e516ab34620331', 'depth': 4, 'input_width': 784, 'output': 10, 'leaf_width': 16, 'buffer_size': 58, 'sizes': 861828}\n",
      "{'run_id': 'cef7d9cd3ea548b783a400984a7145fc', 'depth': 4, 'input_width': 784, 'output': 10, 'leaf_width': 16, 'buffer_size': 58, 'sizes': 861828}\n",
      "{'run_id': '706ca101f6a2446db81d58abdf6e2815', 'depth': 3, 'input_width': 784, 'output': 10, 'leaf_width': 16, 'buffer_size': 58, 'sizes': 429348}\n",
      "{'run_id': '2a116553f512425a9409bd968b9fe8ef', 'depth': 3, 'input_width': 784, 'output': 10, 'leaf_width': 16, 'buffer_size': 58, 'sizes': 429348}\n",
      "{'run_id': '90b23d76307e425ea4ba7d647c7cb7f6', 'depth': 2, 'input_width': 784, 'output': 10, 'leaf_width': 16, 'buffer_size': 58, 'sizes': 213108}\n",
      "{'run_id': '57e917cd181c456bbf3c365b5018a2d6', 'depth': 2, 'input_width': 784, 'output': 10, 'leaf_width': 16, 'buffer_size': 58, 'sizes': 213108}\n",
      "{'run_id': '715fba635c6145b185c29e6aa6b6bcbf', 'depth': 4, 'input_width': 784, 'output': 10, 'leaf_width': 8, 'buffer_size': 42, 'sizes': 454788}\n",
      "{'run_id': '652dc0e8fe0042309b990da5fc377d60', 'depth': 4, 'input_width': 784, 'output': 10, 'leaf_width': 8, 'buffer_size': 42, 'sizes': 454788}\n",
      "{'run_id': '580862314acb40cbb6411391f6def1e1', 'depth': 3, 'input_width': 784, 'output': 10, 'leaf_width': 8, 'buffer_size': 42, 'sizes': 225828}\n",
      "{'run_id': '0c4b701ba2c2434b99a83f0b771b3945', 'depth': 3, 'input_width': 784, 'output': 10, 'leaf_width': 8, 'buffer_size': 42, 'sizes': 225828}\n",
      "{'run_id': '755af7caf9e74fbdbc2dee292dd8b3d1', 'depth': 2, 'input_width': 784, 'output': 10, 'leaf_width': 8, 'buffer_size': 42, 'sizes': 111348}\n",
      "{'run_id': 'e6c2200cd3a942b081e77a4fcbb21df6', 'depth': 2, 'input_width': 784, 'output': 10, 'leaf_width': 8, 'buffer_size': 42, 'sizes': 111348}\n",
      "{'run_id': '9ac931f6215644bf9d22e6fcfc7f179f', 'depth': 4, 'input_width': 784, 'output': 10, 'leaf_width': 4, 'buffer_size': 34, 'sizes': 251268}\n",
      "{'run_id': '69d271a25d744404ad63c43b575192a6', 'depth': 4, 'input_width': 784, 'output': 10, 'leaf_width': 4, 'buffer_size': 34, 'sizes': 251268}\n",
      "{'run_id': '27f4eafb191340f592dfab6992d3700d', 'depth': 3, 'input_width': 784, 'output': 10, 'leaf_width': 4, 'buffer_size': 34, 'sizes': 124068}\n",
      "{'run_id': '9d555e630619470c8e4a6d075ba0e65f', 'depth': 3, 'input_width': 784, 'output': 10, 'leaf_width': 4, 'buffer_size': 34, 'sizes': 124068}\n",
      "{'run_id': '89e999f7bcce4b238cd3bca960ec27da', 'depth': 2, 'input_width': 784, 'output': 10, 'leaf_width': 4, 'buffer_size': 34, 'sizes': 60468}\n",
      "{'run_id': '15d383cd1c044c8cb7cf5b5de6955b13', 'depth': 2, 'input_width': 784, 'output': 10, 'leaf_width': 4, 'buffer_size': 34, 'sizes': 60468}\n"
     ]
    }
   ],
   "source": [
    "for r in result:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e75294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_run = [\n",
    "'27f4eafb191340f592dfab6992d3700d'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e14ec9e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37caab7f4be344919822178023d105cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaf 0 has been replaced with 1\n",
      "Leaf 1 has been replaced with 8\n",
      "Leaf 2 has been replaced with 2\n",
      "Leaf 3 has been replaced with 6\n",
      "Leaf 4 has been replaced with 4\n",
      "Leaf 5 has been replaced with 6\n",
      "Leaf 6 has been replaced with 5\n",
      "Leaf 7 has been replaced with 7\n",
      "[tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])]\n"
     ]
    }
   ],
   "source": [
    "for i in range (0, len(list_of_run)):\n",
    "    run_id = list_of_run[i]\n",
    "    \n",
    "    mlflow.artifacts.download_artifacts(run_id=run_id, dst_path=\".\")\n",
    "    wrapped_model = pickle.load(open(\"./truncated_model.pkl\", \"rb\"))\n",
    "    \n",
    "    original_fastinference = str([-1 if x is None else int(x.argmax()) for x in wrapped_model._fastinference])\n",
    "    \n",
    "    # compress and save result\n",
    "    MODEL_NAME_COMPRESSED = \"mnist_\" + run_id + \"_baseline\"\n",
    "    \n",
    "    n_simplifications = wrapped_model.to(device).simplify_leaves(train_loader)\n",
    "    main(wrapped_model, MODEL_NAME_COMPRESSED, original_fastinference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea81db38",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8d496cabce40d899ad90e780418876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\t 27f4eafb191340f592dfab6992d3700d\n",
      "Depth:\t 3\n",
      "Input:\t 784\n",
      "Output:\t 10\n",
      "Leaf:\t 4\n",
      "Buffer:\t 34\n",
      "1 iteration -  Size: 114064.8 [1, 1, 0.45, 1, 1, 1]\n",
      "2 iteration -  Size: 105033.12000000001 [1, 1, 0.405, 1, 1, 1]\n",
      "3 iteration -  Size: 96904.60800000001 [1, 1, 0.36450000000000005, 1, 1, 1]\n",
      "4 iteration -  Size: 89588.94720000001 [1, 1, 0.32805000000000006, 1, 1, 1]\n",
      "5 iteration -  Size: 83004.85248 [1, 1, 0.29524500000000004, 1, 1, 1]\n",
      "Disabling: _fff.fff.depth\n",
      "Disabling: _fff.fff.node_weights\n",
      "Disabling: _fff.fff.node_biases\n",
      "Disabling: _fff.fff.w1s\n",
      "Disabling: _fff.fff.b1s\n",
      "Disabling: _fff.fff.w2s\n",
      "Disabling: _fff.fff.b2s\n",
      "Activating: torch.Size([7, 784])\n",
      "Activating: torch.Size([7, 1])\n",
      "Activating: torch.Size([8, 784, 4])\n",
      "Activating: torch.Size([8, 4])\n",
      "Activating: torch.Size([8, 4, 10])\n",
      "Activating: torch.Size([8, 10])\n",
      "Epoch [1/7], Step[54/54], Loss: 0.7006\n",
      "Epoch[1]: v_loss: 0.65384 v_acc: 89.83\n",
      "Epoch [2/7], Step[54/54], Loss: 0.5761\n",
      "Epoch[2]: v_loss: 0.62714 v_acc: 89.84\n",
      "Epoch [3/7], Step[54/54], Loss: 0.6536\n",
      "Epoch[3]: v_loss: 0.61227 v_acc: 89.96\n",
      "Epoch [4/7], Step[54/54], Loss: 0.5997\n",
      "Epoch[4]: v_loss: 0.60301 v_acc: 90.06\n",
      "Epoch [5/7], Step[54/54], Loss: 0.6530\n",
      "Epoch[5]: v_loss: 0.59324 v_acc: 90.13\n",
      "Epoch [6/7], Step[54/54], Loss: 0.5658\n",
      "Epoch[6]: v_loss: 0.58429 v_acc: 90.26\n",
      "Epoch [7/7], Step[54/54], Loss: 0.5513\n",
      "Epoch[7]: v_loss: 0.57698 v_acc: 90.51\n",
      "Best model saved at epoch:  7\n",
      "Best acc model saved at epoch:  7\n",
      "Accuracy of the network on the 10000 test images: 90.51 %\n",
      "6 iteration -  Size: 77079.167232 [1, 1, 0.2657205, 1, 1, 1]\n",
      "7 iteration -  Size: 71746.05050879999 [1, 1, 0.23914845, 1, 1, 1]\n",
      "8 iteration -  Size: 66946.24545792 [1, 1, 0.215233605, 1, 1, 1]\n",
      "9 iteration -  Size: 62626.420912128 [1, 1, 0.1937102445, 1, 1, 1]\n",
      "Disabling: _fff.fff.depth\n",
      "Disabling: _fff.fff.node_weights\n",
      "Disabling: _fff.fff.node_biases\n",
      "Disabling: _fff.fff.w1s\n",
      "Disabling: _fff.fff.b1s\n",
      "Disabling: _fff.fff.w2s\n",
      "Disabling: _fff.fff.b2s\n",
      "Activating: torch.Size([7, 784])\n",
      "Activating: torch.Size([7, 1])\n",
      "Activating: torch.Size([8, 784, 4])\n",
      "Activating: torch.Size([8, 4])\n",
      "Activating: torch.Size([8, 4, 10])\n",
      "Activating: torch.Size([8, 10])\n",
      "Epoch [1/7], Step[54/54], Loss: 0.5420\n",
      "Epoch[1]: v_loss: 0.5719 v_acc: 90.57\n",
      "Epoch [2/7], Step[54/54], Loss: 0.5801\n",
      "Epoch[2]: v_loss: 0.56572 v_acc: 90.86\n",
      "Epoch [3/7], Step[54/54], Loss: 0.4823\n",
      "Epoch[3]: v_loss: 0.56219 v_acc: 90.83\n",
      "Epoch [4/7], Step[54/54], Loss: 0.5943\n",
      "Epoch[4]: v_loss: 0.55785 v_acc: 90.93\n",
      "Epoch [5/7], Step[54/54], Loss: 0.4995\n",
      "Epoch[5]: v_loss: 0.55487 v_acc: 90.96\n",
      "Epoch [6/7], Step[54/54], Loss: 0.4965\n",
      "Epoch[6]: v_loss: 0.55121 v_acc: 91.0\n",
      "Epoch [7/7], Step[54/54], Loss: 0.5192\n",
      "Epoch[7]: v_loss: 0.54693 v_acc: 91.01\n",
      "Best model saved at epoch:  7\n",
      "Best acc model saved at epoch:  7\n",
      "Accuracy of the network on the 10000 test images: 91.01 %\n",
      "10 iteration -  Size: 58738.5788209152 [1, 1, 0.17433922005, 1, 1, 1]\n",
      "11 iteration -  Size: 55239.52093882368 [1, 1, 0.156905298045, 1, 1, 1]\n",
      "12 iteration -  Size: 52090.36884494132 [1, 1, 0.1412147682405, 1, 1, 1]\n",
      "13 iteration -  Size: 49256.13196044718 [1, 1, 0.12709329141645, 1, 1, 1]\n",
      "14 iteration -  Size: 46705.31876440246 [1, 1, 0.114383962274805, 1, 1, 1]\n",
      "15 iteration -  Size: 44409.586887962214 [1, 1, 0.10294556604732451, 1, 1, 1]\n",
      "16 iteration -  Size: 45354.38688796222 [0.45, 1, 0.10294556604732451, 1, 1, 1]\n",
      "17 iteration -  Size: 43288.228199166 [0.45, 1, 0.09265100944259205, 1, 1, 1]\n",
      "18 iteration -  Size: 41312.548199166 [0.405, 1, 0.09265100944259205, 1, 1, 1]\n",
      "Disabling: _fff.fff.depth\n",
      "Disabling: _fff.fff.node_weights\n",
      "Disabling: _fff.fff.node_biases\n",
      "Disabling: _fff.fff.w1s\n",
      "Disabling: _fff.fff.b1s\n",
      "Disabling: _fff.fff.w2s\n",
      "Disabling: _fff.fff.b2s\n",
      "Activating: torch.Size([7, 784])\n",
      "Activating: torch.Size([7, 1])\n",
      "Activating: torch.Size([8, 784, 4])\n",
      "Activating: torch.Size([8, 4])\n",
      "Activating: torch.Size([8, 4, 10])\n",
      "Activating: torch.Size([8, 10])\n",
      "Epoch [1/7], Step[54/54], Loss: 0.5787\n",
      "Epoch[1]: v_loss: 0.56607 v_acc: 90.48\n",
      "Epoch [2/7], Step[54/54], Loss: 0.5286\n",
      "Epoch[2]: v_loss: 0.56047 v_acc: 90.64\n",
      "Epoch [3/7], Step[54/54], Loss: 0.5394\n",
      "Epoch[3]: v_loss: 0.55664 v_acc: 90.67\n",
      "Epoch [4/7], Step[54/54], Loss: 0.5455\n",
      "Epoch[4]: v_loss: 0.5535 v_acc: 90.69\n",
      "Epoch [5/7], Step[54/54], Loss: 0.5367\n",
      "Epoch[5]: v_loss: 0.55086 v_acc: 90.71\n",
      "Epoch [6/7], Step[54/54], Loss: 0.5235\n",
      "Epoch[6]: v_loss: 0.54892 v_acc: 90.79\n",
      "Epoch [7/7], Step[54/54], Loss: 0.5258\n",
      "Epoch[7]: v_loss: 0.54626 v_acc: 91.0\n",
      "Best model saved at epoch:  7\n",
      "Best acc model saved at epoch:  7\n",
      "Accuracy of the network on the 10000 test images: 91.0 %\n",
      "19 iteration -  Size: 39453.0053792494 [0.405, 1, 0.08338590849833284, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for i in range (0,len(list_of_run)):\n",
    "    run_id = list_of_run[i]\n",
    "    mlflow.artifacts.download_artifacts(run_id=run_id, dst_path=\".\")\n",
    "    wrapped_model = pickle.load(open(\"./truncated_model.pkl\", \"rb\"))\n",
    "    depth = wrapped_model._fff.fff.depth.item()\n",
    "    input_width = wrapped_model._fff.fff.input_width\n",
    "    leaf_width = wrapped_model._fff.fff.leaf_width\n",
    "    output_width = wrapped_model._fff.fff.output_width\n",
    "    buffer_size = 2*(leaf_width + output_width + 3)\n",
    "    print(\"Run:\\t\", run_id)\n",
    "    print(\"Depth:\\t\", depth)\n",
    "    print(\"Input:\\t\", input_width)\n",
    "    print(\"Output:\\t\", output_width)\n",
    "    print(\"Leaf:\\t\", leaf_width)\n",
    "    print(\"Buffer:\\t\", buffer_size)\n",
    "    \n",
    "    # to reduce the sparsity and train only below a certain tresholds\n",
    "    list_of_sizes = [80, 60, 40]\n",
    "    checked_sizes = [False for x in list_of_sizes]\n",
    "    current_size_index = 0\n",
    "    \n",
    "    start = 0.5\n",
    "    a = start\n",
    "    b = start\n",
    "    sizes=[]\n",
    "    before_trunc_sizes=[]\n",
    "    trunc_sizes=[]\n",
    "\n",
    "    model = wrapped_model.to(device)\n",
    "    \n",
    "    layers_list = []\n",
    "    for i, (name, p) in enumerate(model.named_parameters()):\n",
    "        if (len(list(p.shape)) > 1 and p.requires_grad):\n",
    "            layers_list.append(p)\n",
    "    un, comp, layers = print_size_fc(model, layers_list, [1,1,1,1,1,1])\n",
    "    \n",
    "    MODEL_NAME_COMPRESSED = \"mnist_\" + run_id + \"_compressed_full\"\n",
    "    \n",
    "    layers_sizes = layers.copy()\n",
    "    # Creating a list of 1s with the same length as original_list using multiplication\n",
    "    list_of_sparsity = [1] * len(layers_sizes)\n",
    "    \n",
    "    # Testing time and accuracy\n",
    "    model.eval()\n",
    "    t = time()\n",
    "    train_loss, train_acc = test(model, train_loader)\n",
    "    test_loss, test_acc = test(model, test_loader)\n",
    "    t = time() - t\n",
    "    un, comp, layers_sizes = print_size_fc(model, layers_list, list_of_sparsity)\n",
    "    sizes.append((comp/1000, test_acc, test_acc, t))\n",
    "    \n",
    "    for i in range(1, 100):\n",
    "        # get index of max\n",
    "        index_of_max = np.argmax(layers_sizes)\n",
    "        current_sparsity = list_of_sparsity[index_of_max]\n",
    "\n",
    "        # reduce\n",
    "        if (current_sparsity == 1):\n",
    "            list_of_sparsity[index_of_max] = start - (start * 0.1)\n",
    "        else:\n",
    "            list_of_sparsity[index_of_max] = current_sparsity - (current_sparsity * 0.1)\n",
    "\n",
    "        un, comp, layers_sizes = print_size_fc(model, layers_list, list_of_sparsity)\n",
    "        \n",
    "        if (current_size_index >= len(list_of_sizes)):\n",
    "            break\n",
    "        elif (comp / 1000 < list_of_sizes[current_size_index]):\n",
    "            # compress and save result\n",
    "            MODEL_NAME_COMPRESSED = \"mnist_\" + run_id + \"_compressed_\" + str(list_of_sizes[current_size_index])\n",
    "            current_size_index += 1\n",
    "            model.train()\n",
    "            accuracy = perform_compression(model, layers_list, list_of_sparsity, learning_rate, num_epochs,\n",
    "                                           train_loader, test_loader, device,\n",
    "                                           val_loader=val_loader, model_name=MODEL_NAME_COMPRESSED, given_criterion=criterion)\n",
    "            model.load_state_dict(torch.load(MODEL_NAME_COMPRESSED+\".h5\", map_location='cpu'))\n",
    "            model.eval()\n",
    "            t = time()\n",
    "            train_loss, train_acc = test(model, train_loader)\n",
    "            test_loss, test_acc = test(model, test_loader)\n",
    "            t = time() - t\n",
    "            sizes.append((comp / 1000, test_acc, accuracy, t))\n",
    "        # continue reducing sparsity\n",
    "        print(i, \"iteration - \", \"Size:\", comp, list_of_sparsity)\n",
    "    result.append({'run_id': run_id, 'depth': depth,'input_width':input_width, \n",
    "                   'output': output_width, 'leaf_width':leaf_width,\n",
    "                   'buffer_size': buffer_size, 'sizes': sizes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16a83723",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in result:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f781607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92d516b293b4964ba8c6fda8f095f4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaf 0 has been replaced with 1\n",
      "Leaf 1 has been replaced with 8\n",
      "Leaf 2 has been replaced with 2\n",
      "Leaf 3 has been replaced with 6\n",
      "Leaf 4 has been replaced with 4\n",
      "Leaf 5 has been replaced with 6\n",
      "Leaf 6 has been replaced with 5\n",
      "Leaf 7 has been replaced with 7\n",
      "[tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])]\n",
      "Leaf 0 has been replaced with 1\n",
      "Leaf 1 has been replaced with 8\n",
      "Leaf 2 has been replaced with 2\n",
      "Leaf 3 has been replaced with 6\n",
      "Leaf 4 has been replaced with 4\n",
      "Leaf 5 has been replaced with 6\n",
      "Leaf 6 has been replaced with 5\n",
      "Leaf 7 has been replaced with 7\n",
      "[tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])]\n",
      "Leaf 0 has been replaced with 1\n",
      "Leaf 1 has been replaced with 8\n",
      "Leaf 2 has been replaced with 2\n",
      "Leaf 3 has been replaced with 6\n",
      "Leaf 4 has been replaced with 4\n",
      "Leaf 5 has been replaced with 6\n",
      "Leaf 6 has been replaced with 5\n",
      "Leaf 7 has been replaced with 7\n",
      "[tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])]\n"
     ]
    }
   ],
   "source": [
    "for i in range (0, len(list_of_run)):\n",
    "    run_id = list_of_run[i]\n",
    "    \n",
    "    mlflow.artifacts.download_artifacts(run_id=run_id, dst_path=\".\")\n",
    "    wrapped_model = pickle.load(open(\"./truncated_model.pkl\", \"rb\"))\n",
    "    \n",
    "    original_fastinference = str([-1 if x is None else int(x.argmax()) for x in wrapped_model._fastinference])\n",
    "    \n",
    "    for x in range (0, len(list_of_sizes)):\n",
    "        # compress and save result\n",
    "        MODEL_NAME_COMPRESSED = \"mnist_\" + run_id + \"_compressed_\" + str(list_of_sizes[x])\n",
    "        wrapped_model.load_state_dict(torch.load(MODEL_NAME_COMPRESSED+\".h5\", map_location='cpu'))\n",
    "\n",
    "        n_simplifications = wrapped_model.to(device).simplify_leaves(train_loader)\n",
    "        main(wrapped_model, MODEL_NAME_COMPRESSED, original_fastinference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5a08ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
