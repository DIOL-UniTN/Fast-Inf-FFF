{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "464058eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='leocus4', repo_name='TinyFFF', mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6a0e49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT FOR COMPRESSION\n",
    "import sys\n",
    "sys.path.insert(0, './Compression-Fast-Inf-FFF/')\n",
    "from sparsecompFFF import compress_FF_models, print_size_model\n",
    "from save_torch_model_to_c import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ad620fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Training on {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bbe9647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e36e4acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06b901a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastfeedforward import FFF\n",
    "\n",
    "def train(net, trainloader, epochs, norm_weight=0.0):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    # Define loss and optimizer\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the network for the given number of epochs\n",
    "    for _ in range(epochs):\n",
    "        # Iterate over data\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(net(images), labels)\n",
    "            if norm_weight != 0:\n",
    "                loss += norm_weight * net.fff.w1s.pow(2).sum()\n",
    "                loss += norm_weight * net.fff.w2s.pow(2).sum()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "def test(net, testloader):\n",
    "    \"\"\"Validate the network on the entire test set.\"\"\"\n",
    "    # Define loss and optimizer\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    # Train the network for the given number of epochs\n",
    "    with torch.no_grad():\n",
    "        # Iterate over data\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, input_width, leaf_width, output_width, depth, dropout, region_leak):\n",
    "        super(Net, self).__init__()\n",
    "        self.fff = FFF(input_width, leaf_width, output_width, depth, torch.nn.ReLU(), dropout, train_hardened=True, region_leak=region_leak)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(len(x), -1)\n",
    "        x = self.fff(x)\n",
    "        x = torch.nn.functional.softmax(x, -1)\n",
    "        return x\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.fff.parameters()\n",
    "\n",
    "\n",
    "class FF(torch.nn.Module):\n",
    "    def __init__(self, input_width, layer_width, output_width):\n",
    "        super(FF, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_width, layer_width)\n",
    "        self.fc2 = torch.nn.Linear(layer_width, output_width)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(len(x), -1)\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = torch.nn.functional.softmax(self.fc2(x), -1)\n",
    "        return x\n",
    "\n",
    "    def parameters(self):\n",
    "        return [*self.fc1.parameters(), *self.fc2.parameters()]\n",
    "\n",
    "\n",
    "def compute_n_params(input_width: int, l_w: int, depth: int, output_width: int):\n",
    "    fff = Net(input_width, l_w, output_width, depth, 0, 0)\n",
    "    ff = FF(input_width, l_w, output_width)\n",
    "\n",
    "    n_ff = 0\n",
    "    n_fff = 0\n",
    "    for p in ff.parameters():\n",
    "        n_ff += p.numel()\n",
    "    for i, p in enumerate(fff.parameters()):\n",
    "        print(f\"[{i}-th layer]: {p.shape}\")\n",
    "        n_fff += p.numel()\n",
    "\n",
    "    print(f\"FFF: {n_fff}\\nFF: {n_ff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3e192bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def get_dist(net, testloader):\n",
    "    \"\"\"\n",
    "    Returns the distribution of samples throughout the tree.\n",
    "    \"\"\"\n",
    "\n",
    "    y = []\n",
    "    l = []\n",
    "    with torch.no_grad():\n",
    "        # Iterate over data\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "            outputs, leaves = net.forward(images, return_nodes=True)\n",
    "            y.append(labels)\n",
    "            l.append(leaves)\n",
    "    y = torch.concat(y, 0)\n",
    "    l = torch.concat(l, 0)\n",
    "    return y, l\n",
    "\n",
    "\n",
    "class FFFWrapper(torch.nn.Module):\n",
    "    def __init__(self, fff):\n",
    "        super(FFFWrapper, self).__init__()\n",
    "        self._fff = fff\n",
    "        self._fastinference = [None for i in range(2 ** (self._fff.fff.depth.item()))]\n",
    "\n",
    "    def forward(self, x, return_nodes=False):\n",
    "        \"\"\"\n",
    "        Override the forward method in order to log the data distribution.\n",
    "        \"\"\"\n",
    "        x = x.view(len(x), -1)\n",
    "        original_shape = x.shape\n",
    "        batch_size = x.shape[0]\n",
    "        last_node = torch.zeros(len(x))\n",
    "\n",
    "        current_nodes = torch.zeros((batch_size,), dtype=torch.long, device=x.device)\n",
    "        for i in range(self._fff.fff.depth.item()):\n",
    "            plane_coeffs = self._fff.fff.node_weights.index_select(dim=0, index=current_nodes)\n",
    "            plane_offsets = self._fff.fff.node_biases.index_select(dim=0, index=current_nodes)\n",
    "            plane_coeff_score = torch.bmm(x.unsqueeze(1), plane_coeffs.unsqueeze(-1))\n",
    "            plane_score = plane_coeff_score.squeeze(-1) + plane_offsets\n",
    "            plane_choices = (plane_score.squeeze(-1) >= 0).long()\n",
    "\n",
    "            platform = torch.tensor(2 ** i - 1, dtype=torch.long, device=x.device)\n",
    "            next_platform = torch.tensor(2 ** (i+1) - 1, dtype=torch.long, device=x.device)\n",
    "            current_nodes = (current_nodes - platform) * 2 + plane_choices + next_platform\n",
    "\n",
    "        leaves = current_nodes - next_platform\n",
    "        new_logits = torch.empty((batch_size, self._fff.fff.output_width), dtype=torch.float, device=x.device)\n",
    "        last_node = leaves\n",
    "\n",
    "        for i in range(leaves.shape[0]):\n",
    "            leaf_index = leaves[i]\n",
    "            if self._fastinference[leaf_index] is not None:\n",
    "                new_logits[i] = self._fastinference[leaf_index]\n",
    "            else:\n",
    "                logits = torch.matmul( x[i].unsqueeze(0), self._fff.fff.w1s[leaf_index])\n",
    "                logits += self._fff.fff.b1s[leaf_index].unsqueeze(-2)\n",
    "                activations = self._fff.fff.activation(logits)\n",
    "                new_logits[i] = torch.matmul( activations, self._fff.fff.w2s[leaf_index]).squeeze(-2)\n",
    "\n",
    "        if return_nodes:\n",
    "            return new_logits.view(*original_shape[:-1], self._fff.fff.output_width), last_node\n",
    "        return new_logits.view(*original_shape[:-1], self._fff.fff.output_width)\n",
    "\n",
    "\n",
    "    def simplify_leaves(self, trainloader):\n",
    "        y, leaves = (get_dist(self, trainloader))\n",
    "        y = y.cpu().detach().numpy()\n",
    "        outputs = y.max() + 1\n",
    "        leaves = leaves.cpu().detach().numpy()\n",
    "\n",
    "        n_simplifications = 0\n",
    "        ratios = {}\n",
    "        for l in np.unique(leaves):\n",
    "            ratios[l] = torch.zeros(outputs)\n",
    "            indices = leaves == l\n",
    "\n",
    "            for i in range(outputs):\n",
    "                ratios[l][i] = (np.sum(y[indices] == i) / np.sum(indices))\n",
    "\n",
    "            argmax = np.argmax(ratios[l])\n",
    "            if ratios[l][argmax] > 0.7:\n",
    "                output = torch.zeros(outputs)\n",
    "                output[argmax] = 1\n",
    "                self._fastinference[l] = output\n",
    "                n_simplifications += 1\n",
    "                print(f\"Leaf {l} has been replaced with {argmax}\")\n",
    "        print(self._fastinference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fee5d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFFWrapper(torch.nn.Module):\n",
    "    def __init__(self, fff):\n",
    "        super(FFFWrapper, self).__init__()\n",
    "        self._fff = fff\n",
    "        self._fastinference = [None for i in range(2 ** (self._fff.fff.depth.item()))]\n",
    "\n",
    "    def forward(self, x, return_nodes=False):\n",
    "        \"\"\"\n",
    "        Override the forward method in order to log the data distribution.\n",
    "        \"\"\"\n",
    "        x = x.view(len(x), -1)\n",
    "        original_shape = x.shape\n",
    "        batch_size = x.shape[0]\n",
    "        last_node = torch.zeros(len(x))\n",
    "\n",
    "        current_nodes = torch.zeros((batch_size,), dtype=torch.long, device=x.device)\n",
    "        for i in range(self._fff.fff.depth.item()):\n",
    "            plane_coeffs = self._fff.fff.node_weights.index_select(dim=0, index=current_nodes)\n",
    "            plane_offsets = self._fff.fff.node_biases.index_select(dim=0, index=current_nodes)\n",
    "            plane_coeff_score = torch.bmm(x.unsqueeze(1), plane_coeffs.unsqueeze(-1))\n",
    "            plane_score = plane_coeff_score.squeeze(-1) + plane_offsets\n",
    "            plane_choices = (plane_score.squeeze(-1) >= 0).long()\n",
    "\n",
    "            platform = torch.tensor(2 ** i - 1, dtype=torch.long, device=x.device)\n",
    "            next_platform = torch.tensor(2 ** (i+1) - 1, dtype=torch.long, device=x.device)\n",
    "            current_nodes = (current_nodes - platform) * 2 + plane_choices + next_platform\n",
    "\n",
    "        leaves = current_nodes - next_platform\n",
    "        new_logits = torch.empty((batch_size, self._fff.fff.output_width), dtype=torch.float, device=x.device)\n",
    "        last_node = leaves\n",
    "\n",
    "        for i in range(leaves.shape[0]):\n",
    "            leaf_index = leaves[i]\n",
    "            if self._fastinference[leaf_index] is not None:\n",
    "                new_logits[i] = self._fastinference[leaf_index]\n",
    "            else:\n",
    "                logits = torch.matmul( x[i].unsqueeze(0), self._fff.fff.w1s[leaf_index])\n",
    "                logits += self._fff.fff.b1s[leaf_index].unsqueeze(-2)\n",
    "                activations = self._fff.fff.activation(logits)\n",
    "                new_logits[i] = torch.matmul( activations, self._fff.fff.w2s[leaf_index]).squeeze(-2)\n",
    "\n",
    "        if return_nodes:\n",
    "            return new_logits.view(*original_shape[:-1], self._fff.fff.output_width), last_node\n",
    "        return new_logits.view(*original_shape[:-1], self._fff.fff.output_width)\n",
    "\n",
    "\n",
    "    def simplify_leaves(self, trainloader):\n",
    "        y, leaves = (get_dist(self, trainloader))\n",
    "        y = y.cpu().detach().numpy()\n",
    "        outputs = y.max() + 1\n",
    "        leaves = leaves.cpu().detach().numpy()\n",
    "\n",
    "        n_simplifications = 0\n",
    "        ratios = {}\n",
    "        for l in np.unique(leaves):\n",
    "            ratios[l] = torch.zeros(outputs)\n",
    "            indices = leaves == l\n",
    "\n",
    "            for i in range(outputs):\n",
    "                ratios[l][i] = (np.sum(y[indices] == i) / np.sum(indices))\n",
    "\n",
    "            argmax = np.argmax(ratios[l])\n",
    "            if ratios[l][argmax] > 0.7:\n",
    "                output = torch.zeros(outputs)\n",
    "                output[argmax] = 1\n",
    "                self._fastinference[l] = output\n",
    "                n_simplifications += 1\n",
    "                print(f\"Leaf {l} has been replaced with {argmax}\")\n",
    "        print(self._fastinference)\n",
    "    \n",
    "    def simplify_leaves_full(self, trainloader):\n",
    "        y, leaves = (get_dist(self, trainloader))\n",
    "        y = y.cpu().detach().numpy()\n",
    "        outputs = y.max() + 1\n",
    "        leaves = leaves.cpu().detach().numpy()\n",
    "\n",
    "        n_simplifications = 0\n",
    "        ratios = {}\n",
    "        for l in np.unique(leaves):\n",
    "            ratios[l] = torch.zeros(outputs)\n",
    "            indices = leaves == l\n",
    "\n",
    "            for i in range(outputs):\n",
    "                ratios[l][i] = (np.sum(y[indices] == i) / np.sum(indices))\n",
    "\n",
    "            argmax = np.argmax(ratios[l])\n",
    "            if ratios[l][argmax] >= 0:\n",
    "                output = torch.zeros(outputs)\n",
    "                output[argmax] = 1\n",
    "                self._fastinference[l] = output\n",
    "                n_simplifications += 1\n",
    "                print(f\"Leaf {l} has been replaced with {argmax}\")\n",
    "        print(self._fastinference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94b9bfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trainset': 60000, 'testset': 10000}\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\"\"\"Load CIFAR-10 (training and test set).\"\"\"\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ]\n",
    ")\n",
    "trainset = MNIST(\"../data\", train=True,  download=True, transform=transform)\n",
    "testset = MNIST(\"../data\",  train=False, download=True, transform=transform)\n",
    "\n",
    "# Select class to keep \n",
    "trainloader = DataLoader(trainset, batch_size=1024, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=1024)\n",
    "\n",
    "num_examples = {\"trainset\" : len(trainset), \"testset\" : len(testset)}\n",
    "\n",
    "print(num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42dc558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training variable\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "learning_rate = 0.001\n",
    "num_epochs = 7\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Dataset\n",
    "batch_size = 1024\n",
    "val_size = 5000\n",
    "train_size = len(trainset) - val_size\n",
    "train_ds, val_ds = random_split(trainset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_ds, batch_size, num_workers=4)\n",
    "test_loader = DataLoader(testset, batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c57c37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_run = [\n",
    "'27f4eafb191340f592dfab6992d3700d',\n",
    "]\n",
    "\n",
    "# mlflow.artifacts.download_artifacts(run_id=run_id, dst_path=\".\")\n",
    "# wrapped_model = pickle.load(open(\"./truncated_model.pkl\", \"rb\"))\n",
    "# wrapped_model._fff.fff.depth.item()\n",
    "# wrapped_model._fff.fff.input_width\n",
    "# wrapped_model._fff.fff.leaf_width\n",
    "# wrapped_model._fff.fff.output_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc7c9ea1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a10d126bd5148f1916186fa581cd81e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\t 27f4eafb191340f592dfab6992d3700d\n",
      "Depth:\t 3\n",
      "Input:\t 784\n",
      "Output:\t 10\n",
      "Leaf:\t 4\n",
      "Buffer:\t 34\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for i in range (0,len(list_of_run)):\n",
    "    run_id = list_of_run[i]\n",
    "    \n",
    "    run = mlflow.get_run(run_id)\n",
    "    starting_run_id = run.data.params['starting_run']\n",
    "    starting_run = mlflow.get_run(starting_run_id)\n",
    "    norm_weight = starting_run.data.params['norm_weight']\n",
    "    #print(norm_weight)\n",
    "    \n",
    "    mlflow.artifacts.download_artifacts(run_id=run_id, dst_path=\"./baselines\")\n",
    "    wrapped_model = pickle.load(open(\"./baselines/truncated_model.pkl\", \"rb\"))\n",
    "    depth = wrapped_model._fff.fff.depth.item()\n",
    "    input_width = wrapped_model._fff.fff.input_width\n",
    "    leaf_width = wrapped_model._fff.fff.leaf_width\n",
    "    output_width = wrapped_model._fff.fff.output_width\n",
    "    buffer_size = 2*(leaf_width + output_width + 3)\n",
    "    print(\"Run:\\t\", run_id)\n",
    "    print(\"Depth:\\t\", depth)\n",
    "    print(\"Input:\\t\", input_width)\n",
    "    print(\"Output:\\t\", output_width)\n",
    "    print(\"Leaf:\\t\", leaf_width)\n",
    "    print(\"Buffer:\\t\", buffer_size)\n",
    "    \n",
    "    # to reduce the sparsity and train only below a certain tresholds\n",
    "    list_of_sizes = [100, 90, 80, 70, 60, 50]\n",
    "    checked_sizes = [False for x in list_of_sizes]\n",
    "    current_size_index = 0\n",
    "    \n",
    "    start = 0.5\n",
    "    a = start\n",
    "    b = start\n",
    "    sizes=[]\n",
    "    before_trunc_sizes=[]\n",
    "    trunc_sizes=[]\n",
    "\n",
    "    model = wrapped_model.to(device)\n",
    "    \n",
    "    layers_list = []\n",
    "    for i, (name, p) in enumerate(model.named_parameters()):\n",
    "        if (len(list(p.shape)) > 1 and p.requires_grad):\n",
    "            layers_list.append(p)\n",
    "    un, comp, layers = print_size_model(model, layers_list, [1,1,1,1,1,1])\n",
    "    \n",
    "    result.append({'run_id': run_id, 'depth': depth,'input_width':input_width, \n",
    "                   'output': output_width, 'leaf_width':leaf_width,\n",
    "                   'buffer_size': buffer_size, 'sizes': un})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5777cceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'run_id': '27f4eafb191340f592dfab6992d3700d', 'depth': 3, 'input_width': 784, 'output': 10, 'leaf_width': 4, 'buffer_size': 34, 'sizes': 124068}\n"
     ]
    }
   ],
   "source": [
    "for r in result:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b81494a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target size requested: 50 KB\n",
      "Starting Density of model's parameters: [1, 1, 1, 1, 1, 1]\n",
      "Starting size of the model: 124.068 KB\n",
      "1 iteration -  Size: 114064.8 [1, 1, 0.45, 1, 1, 1]\n",
      "2 iteration -  Size: 105033.12000000001 [1, 1, 0.405, 1, 1, 1]\n",
      "3 iteration -  Size: 96904.60800000001 [1, 1, 0.36450000000000005, 1, 1, 1]\n",
      "4 iteration -  Size: 89588.94720000001 [1, 1, 0.32805000000000006, 1, 1, 1]\n",
      "5 iteration -  Size: 83004.85248 [1, 1, 0.29524500000000004, 1, 1, 1]\n",
      "6 iteration -  Size: 77079.167232 [1, 1, 0.2657205, 1, 1, 1]\n",
      "7 iteration -  Size: 71746.05050879999 [1, 1, 0.23914845, 1, 1, 1]\n",
      "8 iteration -  Size: 66946.24545792 [1, 1, 0.215233605, 1, 1, 1]\n",
      "9 iteration -  Size: 62626.420912128 [1, 1, 0.1937102445, 1, 1, 1]\n",
      "10 iteration -  Size: 58738.5788209152 [1, 1, 0.17433922005, 1, 1, 1]\n",
      "11 iteration -  Size: 55239.52093882368 [1, 1, 0.156905298045, 1, 1, 1]\n",
      "12 iteration -  Size: 52090.36884494132 [1, 1, 0.1412147682405, 1, 1, 1]\n",
      "Disabling: _fff.fff.depth\n",
      "Disabling: _fff.fff.node_weights\n",
      "Disabling: _fff.fff.node_biases\n",
      "Disabling: _fff.fff.w1s\n",
      "Disabling: _fff.fff.b1s\n",
      "Disabling: _fff.fff.w2s\n",
      "Disabling: _fff.fff.b2s\n",
      "Activating: torch.Size([7, 784])\n",
      "Activating: torch.Size([7, 1])\n",
      "Activating: torch.Size([8, 784, 4])\n",
      "Activating: torch.Size([8, 4])\n",
      "Activating: torch.Size([8, 4, 10])\n",
      "Activating: torch.Size([8, 10])\n",
      "Epoch [1/8], Step[54/54], Loss: 0.6838\n",
      "Epoch[1]: v_loss: 0.66644 v_acc: 89.95\n",
      "Epoch [2/8], Step[54/54], Loss: 0.6633\n",
      "Epoch[2]: v_loss: 0.63623 v_acc: 89.96\n",
      "Epoch [3/8], Step[54/54], Loss: 0.6096\n",
      "Epoch[3]: v_loss: 0.61965 v_acc: 89.98\n",
      "Epoch [4/8], Step[54/54], Loss: 0.5751\n",
      "Epoch[4]: v_loss: 0.6089 v_acc: 90.07\n",
      "Epoch [5/8], Step[54/54], Loss: 0.6078\n",
      "Epoch[5]: v_loss: 0.60098 v_acc: 90.12\n",
      "Epoch [6/8], Step[54/54], Loss: 0.5908\n",
      "Epoch[6]: v_loss: 0.59439 v_acc: 90.08\n",
      "Epoch [7/8], Step[54/54], Loss: 0.6130\n",
      "Epoch[7]: v_loss: 0.58761 v_acc: 90.18\n",
      "Epoch [8/8], Step[54/54], Loss: 0.5134\n",
      "Epoch[8]: v_loss: 0.58137 v_acc: 90.32\n",
      "Best model saved at epoch:  8\n",
      "Best acc model saved at epoch:  8\n",
      "Accuracy of the network on the 10000 test images: 90.32 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49256.13196044718"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compress_FF_models(model, 50, train_loader, test_loader, val_loader=val_loader, num_epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e608b9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target size requested: 40 KB\n",
      "Starting Density of model's parameters: [1, 1, 0.12711256377551017, 1, 1, 1]\n",
      "Starting size of the model: 49.227999999999994 KB\n",
      "1 iteration -  Size: 46708.79999999999 [1, 1, 0.11440130739795915, 1, 1, 1]\n",
      "2 iteration -  Size: 44412.719999999994 [1, 1, 0.10296117665816323, 1, 1, 1]\n",
      "3 iteration -  Size: 42346.24799999999 [1, 1, 0.09266505899234691, 1, 1, 1]\n",
      "4 iteration -  Size: 40486.42319999999 [1, 1, 0.08339855309311221, 1, 1, 1]\n",
      "Disabling: _fff.fff.depth\n",
      "Disabling: _fff.fff.node_weights\n",
      "Disabling: _fff.fff.node_biases\n",
      "Disabling: _fff.fff.w1s\n",
      "Disabling: _fff.fff.b1s\n",
      "Disabling: _fff.fff.w2s\n",
      "Disabling: _fff.fff.b2s\n",
      "Activating: torch.Size([7, 784])\n",
      "Activating: torch.Size([7, 1])\n",
      "Activating: torch.Size([8, 784, 4])\n",
      "Activating: torch.Size([8, 4])\n",
      "Activating: torch.Size([8, 4, 10])\n",
      "Activating: torch.Size([8, 10])\n",
      "Epoch [1/8], Step[54/54], Loss: 0.6405\n",
      "Epoch[1]: v_loss: 0.6699 v_acc: 86.45\n",
      "Epoch [2/8], Step[54/54], Loss: 0.7913\n",
      "Epoch[2]: v_loss: 0.81798 v_acc: 79.11\n",
      "Epoch [3/8], Step[54/54], Loss: 0.9465\n",
      "Epoch[3]: v_loss: 0.91445 v_acc: 75.98\n",
      "Epoch [4/8], Step[54/54], Loss: 1.0479\n",
      "Epoch[4]: v_loss: 0.98233 v_acc: 70.1\n",
      "Epoch [5/8], Step[54/54], Loss: 1.0338\n",
      "Epoch[5]: v_loss: 1.06855 v_acc: 66.62\n",
      "Epoch [6/8], Step[54/54], Loss: 1.1068\n",
      "Epoch[6]: v_loss: 1.05372 v_acc: 64.94\n",
      "Epoch [7/8], Step[54/54], Loss: 1.0620\n",
      "Epoch[7]: v_loss: 1.00103 v_acc: 67.33\n",
      "Epoch [8/8], Step[54/54], Loss: 0.9648\n",
      "Epoch[8]: v_loss: 0.94526 v_acc: 70.77\n",
      "Best model saved at epoch:  1\n",
      "Best acc model saved at epoch:  1\n",
      "Accuracy of the network on the 10000 test images: 86.45 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "38812.580879999994"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compress_FF_models(model, 40, train_loader, test_loader, val_loader=val_loader, fastInfLoss=True, fastInfNormWeight=0.0001, num_epochs=8, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14dedf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_fastinference = str([-1 if x is None else int(x.argmax()) for x in model._fastinference])\n",
    "main(model, \"model_to_c\", original_fastinference)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
