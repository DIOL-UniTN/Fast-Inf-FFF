{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "464058eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='leocus4', repo_name='TinyFFF', mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6a0e49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT FOR COMPRESSION\n",
    "import sys\n",
    "sys.path.insert(0, './Compression-Fast-Inf-FFF/')\n",
    "from sparsecompFFF import compress_FF_models, print_size_model\n",
    "from save_torch_model_to_c import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ad620fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = DEVICE\n",
    "print(f\"Training on {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bbe9647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e36e4acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06b901a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastfeedforward import FFF\n",
    "\n",
    "def train(net, trainloader, epochs, norm_weight=0.0):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    # Define loss and optimizer\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the network for the given number of epochs\n",
    "    for _ in range(epochs):\n",
    "        # Iterate over data\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(net(images), labels)\n",
    "            if norm_weight != 0:\n",
    "                loss += norm_weight * net.fff.w1s.pow(2).sum()\n",
    "                loss += norm_weight * net.fff.w2s.pow(2).sum()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "def test(net, testloader):\n",
    "    \"\"\"Validate the network on the entire test set.\"\"\"\n",
    "    # Define loss and optimizer\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    # Train the network for the given number of epochs\n",
    "    with torch.no_grad():\n",
    "        # Iterate over data\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, input_width, leaf_width, output_width, depth, dropout, region_leak):\n",
    "        super(Net, self).__init__()\n",
    "        self.fff = FFF(input_width, leaf_width, output_width, depth, torch.nn.ReLU(), dropout, train_hardened=True, region_leak=region_leak)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(len(x), -1)\n",
    "        x = self.fff(x)\n",
    "        x = torch.nn.functional.softmax(x, -1)\n",
    "        return x\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.fff.parameters()\n",
    "\n",
    "\n",
    "class FF(torch.nn.Module):\n",
    "    def __init__(self, input_width, layer_width, output_width):\n",
    "        super(FF, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_width, layer_width)\n",
    "        self.fc2 = torch.nn.Linear(layer_width, output_width)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(len(x), -1)\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = torch.nn.functional.softmax(self.fc2(x), -1)\n",
    "        return x\n",
    "\n",
    "    def parameters(self):\n",
    "        return [*self.fc1.parameters(), *self.fc2.parameters()]\n",
    "\n",
    "\n",
    "def compute_n_params(input_width: int, l_w: int, depth: int, output_width: int):\n",
    "    fff = Net(input_width, l_w, output_width, depth, 0, 0)\n",
    "    ff = FF(input_width, l_w, output_width)\n",
    "\n",
    "    n_ff = 0\n",
    "    n_fff = 0\n",
    "    for p in ff.parameters():\n",
    "        n_ff += p.numel()\n",
    "    for i, p in enumerate(fff.parameters()):\n",
    "        print(f\"[{i}-th layer]: {p.shape}\")\n",
    "        n_fff += p.numel()\n",
    "\n",
    "    print(f\"FFF: {n_fff}\\nFF: {n_ff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3e192bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def get_dist(net, testloader):\n",
    "    \"\"\"\n",
    "    Returns the distribution of samples throughout the tree.\n",
    "    \"\"\"\n",
    "\n",
    "    y = []\n",
    "    l = []\n",
    "    with torch.no_grad():\n",
    "        # Iterate over data\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "            outputs, leaves = net.forward(images, return_nodes=True)\n",
    "            y.append(labels)\n",
    "            l.append(leaves)\n",
    "    y = torch.concat(y, 0)\n",
    "    l = torch.concat(l, 0)\n",
    "    return y, l\n",
    "\n",
    "\n",
    "class FFFWrapper(torch.nn.Module):\n",
    "    def __init__(self, fff):\n",
    "        super(FFFWrapper, self).__init__()\n",
    "        self._fff = fff\n",
    "        self._fastinference = [None for i in range(2 ** (self._fff.fff.depth.item()))]\n",
    "\n",
    "    def forward(self, x, return_nodes=False):\n",
    "        \"\"\"\n",
    "        Override the forward method in order to log the data distribution.\n",
    "        \"\"\"\n",
    "        x = x.view(len(x), -1)\n",
    "        original_shape = x.shape\n",
    "        batch_size = x.shape[0]\n",
    "        last_node = torch.zeros(len(x))\n",
    "\n",
    "        current_nodes = torch.zeros((batch_size,), dtype=torch.long, device=x.device)\n",
    "        for i in range(self._fff.fff.depth.item()):\n",
    "            plane_coeffs = self._fff.fff.node_weights.index_select(dim=0, index=current_nodes)\n",
    "            plane_offsets = self._fff.fff.node_biases.index_select(dim=0, index=current_nodes)\n",
    "            plane_coeff_score = torch.bmm(x.unsqueeze(1), plane_coeffs.unsqueeze(-1))\n",
    "            plane_score = plane_coeff_score.squeeze(-1) + plane_offsets\n",
    "            plane_choices = (plane_score.squeeze(-1) >= 0).long()\n",
    "\n",
    "            platform = torch.tensor(2 ** i - 1, dtype=torch.long, device=x.device)\n",
    "            next_platform = torch.tensor(2 ** (i+1) - 1, dtype=torch.long, device=x.device)\n",
    "            current_nodes = (current_nodes - platform) * 2 + plane_choices + next_platform\n",
    "\n",
    "        leaves = current_nodes - next_platform\n",
    "        new_logits = torch.empty((batch_size, self._fff.fff.output_width), dtype=torch.float, device=x.device)\n",
    "        last_node = leaves\n",
    "\n",
    "        for i in range(leaves.shape[0]):\n",
    "            leaf_index = leaves[i]\n",
    "            if self._fastinference[leaf_index] is not None:\n",
    "                new_logits[i] = self._fastinference[leaf_index]\n",
    "            else:\n",
    "                logits = torch.matmul( x[i].unsqueeze(0), self._fff.fff.w1s[leaf_index])\n",
    "                logits += self._fff.fff.b1s[leaf_index].unsqueeze(-2)\n",
    "                activations = self._fff.fff.activation(logits)\n",
    "                new_logits[i] = torch.matmul( activations, self._fff.fff.w2s[leaf_index]).squeeze(-2)\n",
    "\n",
    "        if return_nodes:\n",
    "            return new_logits.view(*original_shape[:-1], self._fff.fff.output_width), last_node\n",
    "        return new_logits.view(*original_shape[:-1], self._fff.fff.output_width)\n",
    "\n",
    "\n",
    "    def simplify_leaves(self, trainloader):\n",
    "        y, leaves = (get_dist(self, trainloader))\n",
    "        y = y.cpu().detach().numpy()\n",
    "        outputs = y.max() + 1\n",
    "        leaves = leaves.cpu().detach().numpy()\n",
    "\n",
    "        n_simplifications = 0\n",
    "        ratios = {}\n",
    "        for l in np.unique(leaves):\n",
    "            ratios[l] = torch.zeros(outputs)\n",
    "            indices = leaves == l\n",
    "\n",
    "            for i in range(outputs):\n",
    "                ratios[l][i] = (np.sum(y[indices] == i) / np.sum(indices))\n",
    "\n",
    "            argmax = np.argmax(ratios[l])\n",
    "            if ratios[l][argmax] > 0.7:\n",
    "                output = torch.zeros(outputs)\n",
    "                output[argmax] = 1\n",
    "                self._fastinference[l] = output\n",
    "                n_simplifications += 1\n",
    "                print(f\"Leaf {l} has been replaced with {argmax}\")\n",
    "        print(self._fastinference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fee5d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFFWrapper(torch.nn.Module):\n",
    "    def __init__(self, fff):\n",
    "        super(FFFWrapper, self).__init__()\n",
    "        self._fff = fff\n",
    "        self._fastinference = [None for i in range(2 ** (self._fff.fff.depth.item()))]\n",
    "\n",
    "    def forward(self, x, return_nodes=False):\n",
    "        \"\"\"\n",
    "        Override the forward method in order to log the data distribution.\n",
    "        \"\"\"\n",
    "        x = x.view(len(x), -1)\n",
    "        original_shape = x.shape\n",
    "        batch_size = x.shape[0]\n",
    "        last_node = torch.zeros(len(x))\n",
    "\n",
    "        current_nodes = torch.zeros((batch_size,), dtype=torch.long, device=x.device)\n",
    "        for i in range(self._fff.fff.depth.item()):\n",
    "            plane_coeffs = self._fff.fff.node_weights.index_select(dim=0, index=current_nodes)\n",
    "            plane_offsets = self._fff.fff.node_biases.index_select(dim=0, index=current_nodes)\n",
    "            plane_coeff_score = torch.bmm(x.unsqueeze(1), plane_coeffs.unsqueeze(-1))\n",
    "            plane_score = plane_coeff_score.squeeze(-1) + plane_offsets\n",
    "            plane_choices = (plane_score.squeeze(-1) >= 0).long()\n",
    "\n",
    "            platform = torch.tensor(2 ** i - 1, dtype=torch.long, device=x.device)\n",
    "            next_platform = torch.tensor(2 ** (i+1) - 1, dtype=torch.long, device=x.device)\n",
    "            current_nodes = (current_nodes - platform) * 2 + plane_choices + next_platform\n",
    "\n",
    "        leaves = current_nodes - next_platform\n",
    "        new_logits = torch.empty((batch_size, self._fff.fff.output_width), dtype=torch.float, device=x.device)\n",
    "        last_node = leaves\n",
    "\n",
    "        for i in range(leaves.shape[0]):\n",
    "            leaf_index = leaves[i]\n",
    "            if self._fastinference[leaf_index] is not None:\n",
    "                new_logits[i] = self._fastinference[leaf_index]\n",
    "            else:\n",
    "                logits = torch.matmul( x[i].unsqueeze(0), self._fff.fff.w1s[leaf_index])\n",
    "                logits += self._fff.fff.b1s[leaf_index].unsqueeze(-2)\n",
    "                activations = self._fff.fff.activation(logits)\n",
    "                new_logits[i] = torch.matmul( activations, self._fff.fff.w2s[leaf_index]).squeeze(-2)\n",
    "\n",
    "        if return_nodes:\n",
    "            return new_logits.view(*original_shape[:-1], self._fff.fff.output_width), last_node\n",
    "        return new_logits.view(*original_shape[:-1], self._fff.fff.output_width)\n",
    "\n",
    "\n",
    "    def simplify_leaves(self, trainloader):\n",
    "        y, leaves = (get_dist(self, trainloader))\n",
    "        y = y.cpu().detach().numpy()\n",
    "        outputs = y.max() + 1\n",
    "        leaves = leaves.cpu().detach().numpy()\n",
    "\n",
    "        n_simplifications = 0\n",
    "        ratios = {}\n",
    "        for l in np.unique(leaves):\n",
    "            ratios[l] = torch.zeros(outputs)\n",
    "            indices = leaves == l\n",
    "\n",
    "            for i in range(outputs):\n",
    "                ratios[l][i] = (np.sum(y[indices] == i) / np.sum(indices))\n",
    "\n",
    "            argmax = np.argmax(ratios[l])\n",
    "            if ratios[l][argmax] > 0.7:\n",
    "                output = torch.zeros(outputs)\n",
    "                output[argmax] = 1\n",
    "                self._fastinference[l] = output\n",
    "                n_simplifications += 1\n",
    "                print(f\"Leaf {l} has been replaced with {argmax}\")\n",
    "        print(self._fastinference)\n",
    "    \n",
    "    def simplify_leaves_full(self, trainloader):\n",
    "        y, leaves = (get_dist(self, trainloader))\n",
    "        y = y.cpu().detach().numpy()\n",
    "        outputs = y.max() + 1\n",
    "        leaves = leaves.cpu().detach().numpy()\n",
    "\n",
    "        n_simplifications = 0\n",
    "        ratios = {}\n",
    "        for l in np.unique(leaves):\n",
    "            ratios[l] = torch.zeros(outputs)\n",
    "            indices = leaves == l\n",
    "\n",
    "            for i in range(outputs):\n",
    "                ratios[l][i] = (np.sum(y[indices] == i) / np.sum(indices))\n",
    "\n",
    "            argmax = np.argmax(ratios[l])\n",
    "            if ratios[l][argmax] >= 0:\n",
    "                output = torch.zeros(outputs)\n",
    "                output[argmax] = 1\n",
    "                self._fastinference[l] = output\n",
    "                n_simplifications += 1\n",
    "                print(f\"Leaf {l} has been replaced with {argmax}\")\n",
    "        print(self._fastinference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94b9bfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "class HarDataset(Dataset):\n",
    "    def __init__(self, fold=\"train\"):\n",
    "        self.data = pickle.load(open(f\"../data/har/{fold}_data.summary\", \"rb\"), encoding=\"latin1\")\n",
    "        self.labels = pickle.load(open(f\"../data/har/{fold}_labels.summary\", \"rb\"), encoding=\"latin1\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.labels[index]\n",
    "        y = np.argmax(y, axis=0)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a901b59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trainset': 16563, 'valset': 2070, 'testset': 2070}\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "trainset = HarDataset(\"train\")\n",
    "valset = HarDataset(\"val\")\n",
    "testset = HarDataset(\"test\")\n",
    "\n",
    "# Select class to keep \n",
    "train_loader = DataLoader(trainset, batch_size=1024, shuffle=True)\n",
    "val_loader = DataLoader(valset, batch_size=1024)\n",
    "test_loader = DataLoader(testset, batch_size=1024)\n",
    "\n",
    "num_examples = {\"trainset\" : len(trainset), \"valset\" : len(valset), \"testset\" : len(testset)}\n",
    "\n",
    "print(num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42dc558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training variable\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "learning_rate = 0.001\n",
    "num_epochs = 7\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c57c37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_run = [\n",
    "'ca491bebb1104d03836c45bff81f6160',\n",
    "]\n",
    "\n",
    "# mlflow.artifacts.download_artifacts(run_id=run_id, dst_path=\".\")\n",
    "# wrapped_model = pickle.load(open(\"./truncated_model.pkl\", \"rb\"))\n",
    "# wrapped_model._fff.fff.depth.item()\n",
    "# wrapped_model._fff.fff.input_width\n",
    "# wrapped_model._fff.fff.leaf_width\n",
    "# wrapped_model._fff.fff.output_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc7c9ea1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "561f08f51897477f97fa1f86eea6bea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n",
      "Run:\t ca491bebb1104d03836c45bff81f6160\n",
      "Depth:\t 3\n",
      "Input:\t 300\n",
      "Output:\t 6\n",
      "Leaf:\t 16\n",
      "Buffer:\t 50\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for i in range (0,len(list_of_run)):\n",
    "    run_id = list_of_run[i]\n",
    "    \n",
    "    run = mlflow.get_run(run_id)\n",
    "    starting_run_id = run.data.params['starting_run']\n",
    "    starting_run = mlflow.get_run(starting_run_id)\n",
    "    norm_weight = starting_run.data.params['norm_weight']\n",
    "    #print(norm_weight)\n",
    "    \n",
    "    mlflow.artifacts.download_artifacts(run_id=run_id, dst_path=\"./baselines\")\n",
    "    wrapped_model = pickle.load(open(\"./baselines/truncated_model.pkl\", \"rb\"))\n",
    "    depth = wrapped_model._fff.fff.depth.item()\n",
    "    input_width = wrapped_model._fff.fff.input_width\n",
    "    leaf_width = wrapped_model._fff.fff.leaf_width\n",
    "    output_width = wrapped_model._fff.fff.output_width\n",
    "    buffer_size = 2*(leaf_width + output_width + 3)\n",
    "    print(\"Run:\\t\", run_id)\n",
    "    print(\"Depth:\\t\", depth)\n",
    "    print(\"Input:\\t\", input_width)\n",
    "    print(\"Output:\\t\", output_width)\n",
    "    print(\"Leaf:\\t\", leaf_width)\n",
    "    print(\"Buffer:\\t\", buffer_size)\n",
    "    \n",
    "    # to reduce the sparsity and train only below a certain tresholds\n",
    "    list_of_sizes = [100, 90, 80, 70, 60, 50]\n",
    "    checked_sizes = [False for x in list_of_sizes]\n",
    "    current_size_index = 0\n",
    "    \n",
    "    start = 0.5\n",
    "    a = start\n",
    "    b = start\n",
    "    sizes=[]\n",
    "    before_trunc_sizes=[]\n",
    "    trunc_sizes=[]\n",
    "\n",
    "    model = wrapped_model.to(device)\n",
    "    \n",
    "    layers_list = []\n",
    "    for i, (name, p) in enumerate(model.named_parameters()):\n",
    "        if (len(list(p.shape)) > 1 and p.requires_grad):\n",
    "            layers_list.append(p)\n",
    "    un, comp, layers = print_size_model(model, layers_list, [1,1,1,1,1,1])\n",
    "    \n",
    "    result.append({'run_id': run_id, 'depth': depth,'input_width':input_width, \n",
    "                   'output': output_width, 'leaf_width':leaf_width,\n",
    "                   'buffer_size': buffer_size, 'sizes': un})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5777cceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'run_id': 'ca491bebb1104d03836c45bff81f6160', 'depth': 3, 'input_width': 300, 'output': 6, 'leaf_width': 16, 'buffer_size': 50, 'sizes': 165812}\n"
     ]
    }
   ],
   "source": [
    "for r in result:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b81494a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target size requested: 50 KB\n",
      "Starting Density of model's parameters: [1, 1, 1, 1, 1, 1]\n",
      "Starting size of the model: 165.812 KB\n",
      "1 iteration -  Size: 150484.0 [1, 1, 0.45, 1, 1, 1]\n",
      "2 iteration -  Size: 136660.0 [1, 1, 0.405, 1, 1, 1]\n",
      "3 iteration -  Size: 124218.40000000001 [1, 1, 0.36450000000000005, 1, 1, 1]\n",
      "4 iteration -  Size: 113020.96000000002 [1, 1, 0.32805000000000006, 1, 1, 1]\n",
      "5 iteration -  Size: 102943.26400000001 [1, 1, 0.29524500000000004, 1, 1, 1]\n",
      "6 iteration -  Size: 93873.33760000001 [1, 1, 0.2657205, 1, 1, 1]\n",
      "7 iteration -  Size: 85710.40384 [1, 1, 0.23914845, 1, 1, 1]\n",
      "8 iteration -  Size: 78363.763456 [1, 1, 0.215233605, 1, 1, 1]\n",
      "9 iteration -  Size: 71751.7871104 [1, 1, 0.1937102445, 1, 1, 1]\n",
      "10 iteration -  Size: 65801.00839936 [1, 1, 0.17433922005, 1, 1, 1]\n",
      "11 iteration -  Size: 60445.307559424 [1, 1, 0.156905298045, 1, 1, 1]\n",
      "12 iteration -  Size: 55625.1768034816 [1, 1, 0.1412147682405, 1, 1, 1]\n",
      "13 iteration -  Size: 51287.05912313344 [1, 1, 0.12709329141645, 1, 1, 1]\n",
      "Disabling: _fff.fff.depth\n",
      "Disabling: _fff.fff.node_weights\n",
      "Disabling: _fff.fff.node_biases\n",
      "Disabling: _fff.fff.w1s\n",
      "Disabling: _fff.fff.b1s\n",
      "Disabling: _fff.fff.w2s\n",
      "Disabling: _fff.fff.b2s\n",
      "Activating: torch.Size([7, 300])\n",
      "Activating: torch.Size([7, 1])\n",
      "Activating: torch.Size([8, 300, 16])\n",
      "Activating: torch.Size([8, 16])\n",
      "Activating: torch.Size([8, 16, 6])\n",
      "Activating: torch.Size([8, 6])\n",
      "Epoch [1/8], Step[17/17], Loss: 0.8696\n",
      "Epoch[1]: v_loss: 0.58657 v_acc: 74.92754\n",
      "Epoch [2/8], Step[17/17], Loss: 0.7730\n",
      "Epoch[2]: v_loss: 0.56936 v_acc: 74.92754\n",
      "Epoch [3/8], Step[17/17], Loss: 0.8965\n",
      "Epoch[3]: v_loss: 0.56335 v_acc: 75.21739\n",
      "Epoch [4/8], Step[17/17], Loss: 0.8640\n",
      "Epoch[4]: v_loss: 0.55945 v_acc: 78.50242\n",
      "Epoch [5/8], Step[17/17], Loss: 0.8163\n",
      "Epoch[5]: v_loss: 0.55895 v_acc: 78.9372\n",
      "Epoch [6/8], Step[17/17], Loss: 0.9563\n",
      "Epoch[6]: v_loss: 0.55668 v_acc: 79.17874\n",
      "Epoch [7/8], Step[17/17], Loss: 0.8833\n",
      "Epoch[7]: v_loss: 0.55593 v_acc: 78.88889\n",
      "Epoch [8/8], Step[17/17], Loss: 0.8296\n",
      "Epoch[8]: v_loss: 0.55468 v_acc: 78.69565\n",
      "Best model saved at epoch:  8\n",
      "Best acc model saved at epoch:  6\n",
      "Accuracy of the network on the 10000 test images: 78.69565217391305 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47382.7532108201"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compress_FF_models(model, 50, train_loader, test_loader, val_loader=val_loader, num_epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e608b9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target size requested: 40 KB\n",
      "Starting Density of model's parameters: [1, 1, 0.11440104166666665, 1, 1, 1]\n",
      "Starting size of the model: 47.355999999999995 KB\n",
      "1 iteration -  Size: 43873.59999999999 [1, 1, 0.10296093749999999, 1, 1, 1]\n",
      "2 iteration -  Size: 40710.64 [1, 1, 0.09266484374999999, 1, 1, 1]\n",
      "Disabling: _fff.fff.depth\n",
      "Disabling: _fff.fff.node_weights\n",
      "Disabling: _fff.fff.node_biases\n",
      "Disabling: _fff.fff.w1s\n",
      "Disabling: _fff.fff.b1s\n",
      "Disabling: _fff.fff.w2s\n",
      "Disabling: _fff.fff.b2s\n",
      "Activating: torch.Size([7, 300])\n",
      "Activating: torch.Size([7, 1])\n",
      "Activating: torch.Size([8, 300, 16])\n",
      "Activating: torch.Size([8, 16])\n",
      "Activating: torch.Size([8, 16, 6])\n",
      "Activating: torch.Size([8, 6])\n",
      "Epoch [1/8], Step[17/17], Loss: 0.8819\n",
      "Epoch[1]: v_loss: 0.57077 v_acc: 78.55072\n",
      "Epoch [2/8], Step[17/17], Loss: 0.8390\n",
      "Epoch[2]: v_loss: 0.56509 v_acc: 77.19807\n",
      "Epoch [3/8], Step[17/17], Loss: 1.0079\n",
      "Epoch[3]: v_loss: 0.61154 v_acc: 76.18357\n",
      "Epoch [4/8], Step[17/17], Loss: 0.9212\n",
      "Epoch[4]: v_loss: 0.64747 v_acc: 74.78261\n",
      "Epoch [5/8], Step[17/17], Loss: 0.8879\n",
      "Epoch[5]: v_loss: 0.64046 v_acc: 74.2029\n"
     ]
    }
   ],
   "source": [
    "compress_FF_models(model, 40, train_loader, test_loader, val_loader=val_loader, fastInfLoss=True, fastInfNormWeight=0.0001, num_epochs=8, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dedf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_fastinference = str([-1 if x is None else int(x.argmax()) for x in model._fastinference])\n",
    "main(model, \"model_to_c\", original_fastinference)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
